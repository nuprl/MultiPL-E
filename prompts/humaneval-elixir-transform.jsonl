{"name": "HumanEval_0_has_close_elements", "language": "elixir", "prompt": "# Check if in given list of numbers, are any two numbers closer to each other than\n# given threshold.\n# >>> HumanEval.has_close_elements([1.0, 2.0, 3.0], 0.5)\n# false\n# >>> HumanEval.has_close_elements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n# true\n\ndefmodule HumanEval do\n  def candidate(numbers, threshold), do: has_close_elements(numbers, threshold)\n  def has_close_elements(numbers, threshold) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_0_has_close_elements.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'has_close_elements' do\n    assert true == HumanEval.candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.3)\n    assert false == HumanEval.candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2], 0.05)\n    assert true == HumanEval.candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.95)\n    assert false == HumanEval.candidate([1.0, 2.0, 5.9, 4.0, 5.0], 0.8)\n    assert true == HumanEval.candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0], 0.1)\n    assert true == HumanEval.candidate([1.1, 2.2, 3.1, 4.1, 5.1], 1.0)\n    assert false == HumanEval.candidate([1.1, 2.2, 3.1, 4.1, 5.1], 0.5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_100_make_a_pile", "language": "elixir", "prompt": "# Given a positive integer n, you have to make a pile of n levels of stones.\n# The first level has n stones.\n# The number of stones in the next level is:\n# - the next odd number if n is odd.\n# - the next even number if n is even.\n# Return the number of stones in each level in a list, where element at index\n# i represents the number of stones in the level (i+1).\n# Examples:\n# >>> HumanEval.make_a_pile(3)\n# [3, 5, 7]\n\ndefmodule HumanEval do\n  def candidate(n), do: make_a_pile(n)\n  def make_a_pile(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_100_make_a_pile.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'make_a_pile' do\n    assert [3, 5, 7] == HumanEval.candidate(3)\n    assert [4, 6, 8, 10] == HumanEval.candidate(4)\n    assert [5, 7, 9, 11, 13] == HumanEval.candidate(5)\n    assert [6, 8, 10, 12, 14, 16] == HumanEval.candidate(6)\n    assert [8, 10, 12, 14, 16, 18, 20, 22] == HumanEval.candidate(8)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_101_words_string", "language": "elixir", "prompt": "# You will be given a string of words separated by commas or spaces. Your task is\n# to split the string into words and return an array of the words.\n# For example:\n# >>> HumanEval.words_string(\"Hi, my name is John\")\n# [\"Hi\", \"my\", \"name\", \"is\", \"John\"]\n# >>> HumanEval.words_string(\"One, two, three, four, five, six\")\n# [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"]\n\ndefmodule HumanEval do\n  def candidate(s), do: words_string(s)\n  def words_string(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_101_words_string.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'words_string' do\n    assert [\"Hi\", \"my\", \"name\", \"is\", \"John\"] == HumanEval.candidate(\"Hi, my name is John\")\n    assert [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"] == HumanEval.candidate(\"One, two, three, four, five, six\")\n    assert [\"Hi\", \"my\", \"name\"] == HumanEval.candidate(\"Hi, my name\")\n    assert [\"One\", \"two\", \"three\", \"four\", \"five\", \"six\"] == HumanEval.candidate(\"One,, two, three, four, five, six,\")\n    assert [] == HumanEval.candidate(\"\")\n    assert [\"ahmed\", \"gamal\"] == HumanEval.candidate(\"ahmed     , gamal\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_102_choose_num", "language": "elixir", "prompt": "# This function takes two positive numbers x and y and returns the\n# biggest even integer number that is in the range [x, y] inclusive. If \n# there's no such number, then the function should return -1.\n# For example:\n# >>> HumanEval.choose_num(12, 15)\n# 14\n# >>> HumanEval.choose_num(13, 12)\n# -1\n\ndefmodule HumanEval do\n  def candidate(x, y), do: choose_num(x, y)\n  def choose_num(x, y) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_102_choose_num.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'choose_num' do\n    assert 14 == HumanEval.candidate(12, 15)\n    assert -1 == HumanEval.candidate(13, 12)\n    assert 12354 == HumanEval.candidate(33, 12354)\n    assert -1 == HumanEval.candidate(5234, 5233)\n    assert 28 == HumanEval.candidate(6, 29)\n    assert -1 == HumanEval.candidate(27, 10)\n    assert -1 == HumanEval.candidate(7, 7)\n    assert 546 == HumanEval.candidate(546, 546)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_103_rounded_avg", "language": "elixir", "prompt": "# You are given two positive integers n and m, and your task is to compute the\n# average of the integers from n through m (including n and m). \n# Round the answer to the nearest integer and convert that to binary.\n# If n is greater than m, return -1.\n# Example:\n# >>> HumanEval.rounded_avg(1, 5)\n# \"0b11\"\n# >>> HumanEval.rounded_avg(7, 5)\n# -1\n# >>> HumanEval.rounded_avg(10, 20)\n# \"0b1111\"\n# >>> HumanEval.rounded_avg(20, 33)\n# \"0b11010\"\n\ndefmodule HumanEval do\n  def candidate(n, m), do: rounded_avg(n, m)\n  def rounded_avg(n, m) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_103_rounded_avg.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'rounded_avg' do\n    assert \"0b11\" == HumanEval.candidate(1, 5)\n    assert \"0b1010\" == HumanEval.candidate(7, 13)\n    assert \"0b1111001010\" == HumanEval.candidate(964, 977)\n    assert \"0b1111100100\" == HumanEval.candidate(996, 997)\n    assert \"0b1011000010\" == HumanEval.candidate(560, 851)\n    assert \"0b101101110\" == HumanEval.candidate(185, 546)\n    assert \"0b110101101\" == HumanEval.candidate(362, 496)\n    assert \"0b1001110010\" == HumanEval.candidate(350, 902)\n    assert \"0b11010111\" == HumanEval.candidate(197, 233)\n    assert -1 == HumanEval.candidate(7, 5)\n    assert -1 == HumanEval.candidate(5, 1)\n    assert \"0b101\" == HumanEval.candidate(5, 5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_104_unique_digits", "language": "elixir", "prompt": "# Given a list of positive integers x. return a sorted list of all \n# elements that hasn't any even digit.\n# Note: Returned list should be sorted in increasing order.\n# For example:\n# >>> HumanEval.unique_digits([15, 33, 1422, 1])\n# [1, 15, 33]\n# >>> HumanEval.unique_digits([152, 323, 1422, 10])\n# []\n\ndefmodule HumanEval do\n  def candidate(x), do: unique_digits(x)\n  def unique_digits(x) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_104_unique_digits.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'unique_digits' do\n    assert [1, 15, 33] == HumanEval.candidate([15, 33, 1422, 1])\n    assert [] == HumanEval.candidate([152, 323, 1422, 10])\n    assert [111, 151] == HumanEval.candidate([12345, 2033, 111, 151])\n    assert [31, 135] == HumanEval.candidate([135, 103, 31])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_105_by_length", "language": "elixir", "prompt": "# Given an array of integers, sort the integers that are between 1 and 9 inclusive,\n# reverse the resulting array, and then replace each digit by its corresponding name from\n# \"One\", \"Two\", \"Three\", \"Four\", \"Five\", \"Six\", \"Seven\", \"Eight\", \"Nine\".\n# For example:\n# >>> HumanEval.by_length([2, 1, 1, 4, 5, 8, 2, 3])\n# [\"Eight\", \"Five\", \"Four\", \"Three\", \"Two\", \"Two\", \"One\", \"One\"]\n# If the array is empty, return an empty array:\n# >>> HumanEval.by_length([])\n# []\n# If the array has any strange number ignore it:\n# >>> HumanEval.by_length([1, -1, 55])\n# [\"One\"]\n\ndefmodule HumanEval do\n  def candidate(arr), do: by_length(arr)\n  def by_length(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_105_by_length.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'by_length' do\n    assert [\"Eight\", \"Five\", \"Four\", \"Three\", \"Two\", \"Two\", \"One\", \"One\"] == HumanEval.candidate([2, 1, 1, 4, 5, 8, 2, 3])\n    assert [] == HumanEval.candidate([])\n    assert [\"One\"] == HumanEval.candidate([1, -1, 55])\n    assert [\"Three\", \"Two\", \"One\"] == HumanEval.candidate([1, -1, 3, 2])\n    assert [\"Nine\", \"Eight\", \"Four\"] == HumanEval.candidate([9, 4, 8])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_106_f", "language": "elixir", "prompt": "# Implement the function f that takes n as a parameter,\n# and returns a list of size n, such that the value of the element at index i is the factorial of i if i is even\n# or the sum of numbers from 1 to i otherwise.\n# i starts from 1.\n# the factorial of i is the multiplication of the numbers from 1 to i (1 * 2 * ... * i).\n# Example:\n# >>> HumanEval.f(5)\n# [1, 2, 6, 24, 15]\n\ndefmodule HumanEval do\n  def candidate(n), do: f(n)\n  def f(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_106_f.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'f' do\n    assert [1, 2, 6, 24, 15] == HumanEval.candidate(5)\n    assert [1, 2, 6, 24, 15, 720, 28] == HumanEval.candidate(7)\n    assert [1] == HumanEval.candidate(1)\n    assert [1, 2, 6] == HumanEval.candidate(3)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_107_even_odd_palindrome", "language": "elixir", "prompt": "# Given a positive integer n, return a tuple that has the number of even and odd\n# integer palindromes that fall within the range(1, n), inclusive.\n# Example 1:\n# >>> HumanEval.even_odd_palindrome(3)\n# {1, 2}\n# Explanation:\n# Integer palindrome are 1, 2, 3. one of them is even, and two of them are odd.\n# Example 2:\n# >>> HumanEval.even_odd_palindrome(12)\n# {4, 6}\n# Explanation:\n# Integer palindrome are 1, 2, 3, 4, 5, 6, 7, 8, 9, 11. four of them are even, and 6 of them are odd.\n# Note:\n# 1. 1 <= n <= 10^3\n# 2. returned tuple has the number of even and odd integer palindromes respectively.\n\ndefmodule HumanEval do\n  def candidate(n), do: even_odd_palindrome(n)\n  def even_odd_palindrome(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_107_even_odd_palindrome.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'even_odd_palindrome' do\n    assert {8, 13} == HumanEval.candidate(123)\n    assert {4, 6} == HumanEval.candidate(12)\n    assert {1, 2} == HumanEval.candidate(3)\n    assert {6, 8} == HumanEval.candidate(63)\n    assert {5, 6} == HumanEval.candidate(25)\n    assert {4, 6} == HumanEval.candidate(19)\n    assert {4, 5} == HumanEval.candidate(9)\n    assert {0, 1} == HumanEval.candidate(1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_108_count_nums", "language": "elixir", "prompt": "# Write a function count_nums which takes an array of integers and returns\n# the number of elements which has a sum of digits > 0.\n# If a number is negative, then its first signed digit will be negative:\n# e.g. -123 has signed digits -1, 2, and 3.\n# >>> HumanEval.count_nums([])\n# 0\n# >>> HumanEval.count_nums([-1, 11, -11])\n# 1\n# >>> HumanEval.count_nums([1, 1, 2])\n# 3\n\ndefmodule HumanEval do\n  def candidate(arr), do: count_nums(arr)\n  def count_nums(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_108_count_nums.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'count_nums' do\n    assert 0 == HumanEval.candidate([])\n    assert 0 == HumanEval.candidate([-1, -2, 0])\n    assert 6 == HumanEval.candidate([1, 1, 2, -2, 3, 4, 5])\n    assert 5 == HumanEval.candidate([1, 6, 9, -6, 0, 1, 5])\n    assert 4 == HumanEval.candidate([1, 100, 98, -7, 1, -1])\n    assert 5 == HumanEval.candidate([12, 23, 34, -45, -56, 0])\n    assert 1 == HumanEval.candidate([0, 1])\n    assert 1 == HumanEval.candidate([1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_109_move_one_ball", "language": "elixir", "prompt": "# We have an array 'arr' of N integers arr[1], arr[2], ..., arr[N].The\n# numbers in the array will be randomly ordered. Your task is to determine if\n# it is possible to get an array sorted in non-decreasing order by performing \n# the following operation on the given array:\n# You are allowed to perform right shift operation any number of times.\n# One right shift operation means shifting all elements of the array by one\n# position in the right direction. The last element of the array will be moved to\n# the starting position in the array i.e. 0th index. \n# If it is possible to obtain the sorted array by performing the above operation\n# then return True else return False.\n# If the given array is empty then return True.\n# Note: The given list is guaranteed to have unique elements.\n# For Example:\n# >>> HumanEval.move_one_ball([3, 4, 5, 1, 2])\n# true\n# Explanation: By performin 2 right shift operations, non-decreasing order can\n# be achieved for the given array.\n# >>> HumanEval.move_one_ball([3, 5, 4, 1, 2])\n# false\n# Explanation:It is not possible to get non-decreasing order for the given\n# array by performing any number of right shift operations.\n\ndefmodule HumanEval do\n  def candidate(arr), do: move_one_ball(arr)\n  def move_one_ball(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_109_move_one_ball.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'move_one_ball' do\n    assert true == HumanEval.candidate([3, 4, 5, 1, 2])\n    assert true == HumanEval.candidate([3, 5, 10, 1, 2])\n    assert false == HumanEval.candidate([4, 3, 1, 2])\n    assert false == HumanEval.candidate([3, 5, 4, 1, 2])\n    assert true == HumanEval.candidate([])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_10_make_palindrome", "language": "elixir", "prompt": "# Find the shortest palindrome that begins with a supplied string.\n# Algorithm idea is simple:\n# - Find the longest postfix of supplied string that is a palindrome.\n# - Append to the end of the string reverse of a string prefix that comes before the palindromic suffix.\n# >>> HumanEval.make_palindrome(\"\")\n# \"\"\n# >>> HumanEval.make_palindrome(\"cat\")\n# \"catac\"\n# >>> HumanEval.make_palindrome(\"cata\")\n# \"catac\"\n\ndefmodule HumanEval do\n  def candidate(string), do: make_palindrome(string)\n  def make_palindrome(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_10_make_palindrome.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'make_palindrome' do\n    assert \"\" == HumanEval.candidate(\"\")\n    assert \"x\" == HumanEval.candidate(\"x\")\n    assert \"xyzyx\" == HumanEval.candidate(\"xyz\")\n    assert \"xyx\" == HumanEval.candidate(\"xyx\")\n    assert \"jerryrrej\" == HumanEval.candidate(\"jerry\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_110_exchange", "language": "elixir", "prompt": "# In this problem, you will implement a function that takes two lists of numbers,\n# and determines whether it is possible to perform an exchange of elements\n# between them to make lst1 a list of only even numbers.\n# There is no limit on the number of exchanged elements between lst1 and lst2.\n# If it is possible to exchange elements between the lst1 and lst2 to make\n# all the elements of lst1 to be even, return \"YES\".\n# Otherwise, return \"NO\".\n# For example:\n# >>> HumanEval.exchange([1, 2, 3, 4], [1, 2, 3, 4])\n# \"YES\"\n# >>> HumanEval.exchange([1, 2, 3, 4], [1, 5, 3, 4])\n# \"NO\"\n# It is assumed that the input lists will be non-empty.\n\ndefmodule HumanEval do\n  def candidate(lst1, lst2), do: exchange(lst1, lst2)\n  def exchange(lst1, lst2) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_110_exchange.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'exchange' do\n    assert \"YES\" == HumanEval.candidate([1, 2, 3, 4], [1, 2, 3, 4])\n    assert \"NO\" == HumanEval.candidate([1, 2, 3, 4], [1, 5, 3, 4])\n    assert \"YES\" == HumanEval.candidate([1, 2, 3, 4], [2, 1, 4, 3])\n    assert \"YES\" == HumanEval.candidate([5, 7, 3], [2, 6, 4])\n    assert \"NO\" == HumanEval.candidate([5, 7, 3], [2, 6, 3])\n    assert \"NO\" == HumanEval.candidate([3, 2, 6, 1, 8, 9], [3, 5, 5, 1, 1, 1])\n    assert \"YES\" == HumanEval.candidate([100, 200], [200, 200])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_111_histogram", "language": "elixir", "prompt": "# Given a string representing a space separated lowercase letters, return a dictionary\n# of the letter with the most repetition and containing the corresponding count.\n# If several letters have the same occurrence, return all of them.\n# Example:\n# >>> HumanEval.histogram(\"a b c\")\n# %{\"a\" => 1, \"b\" => 1, \"c\" => 1}\n# >>> HumanEval.histogram(\"a b b a\")\n# %{\"a\" => 2, \"b\" => 2}\n# >>> HumanEval.histogram(\"a b c a b\")\n# %{\"a\" => 2, \"b\" => 2}\n# >>> HumanEval.histogram(\"b b b b a\")\n# %{\"b\" => 4}\n# >>> HumanEval.histogram(\"\")\n# %{}\n\ndefmodule HumanEval do\n  def candidate(test), do: histogram(test)\n  def histogram(test) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_111_histogram.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'histogram' do\n    assert %{\"a\" => 2, \"b\" => 2} == HumanEval.candidate(\"a b b a\")\n    assert %{\"a\" => 2, \"b\" => 2} == HumanEval.candidate(\"a b c a b\")\n    assert %{\"a\" => 1, \"b\" => 1, \"c\" => 1, \"d\" => 1, \"g\" => 1} == HumanEval.candidate(\"a b c d g\")\n    assert %{\"r\" => 1, \"t\" => 1, \"g\" => 1} == HumanEval.candidate(\"r t g\")\n    assert %{\"b\" => 4} == HumanEval.candidate(\"b b b b a\")\n    assert %{\"r\" => 1, \"t\" => 1, \"g\" => 1} == HumanEval.candidate(\"r t g\")\n    assert %{} == HumanEval.candidate(\"\")\n    assert %{\"a\" => 1} == HumanEval.candidate(\"a\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_112_reverse_delete", "language": "elixir", "prompt": "# Task\n# We are given two strings s and c, you have to deleted all the characters in s that are equal to any character in c\n# then check if the result string is palindrome.\n# A string is called palindrome if it reads the same backward as forward.\n# You should return a tuple containing the result string and True/False for the check.\n# Example\n# >>> HumanEval.reverse_delete(\"abcde\", \"ae\")\n# {\"bcd\", false}\n# >>> HumanEval.reverse_delete(\"abcdef\", \"b\")\n# {\"acdef\", false}\n# >>> HumanEval.reverse_delete(\"abcdedcba\", \"ab\")\n# {\"cdedc\", true}\n\ndefmodule HumanEval do\n  def candidate(s, c), do: reverse_delete(s, c)\n  def reverse_delete(s, c) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_112_reverse_delete.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'reverse_delete' do\n    assert {\"bcd\", false} == HumanEval.candidate(\"abcde\", \"ae\")\n    assert {\"acdef\", false} == HumanEval.candidate(\"abcdef\", \"b\")\n    assert {\"cdedc\", true} == HumanEval.candidate(\"abcdedcba\", \"ab\")\n    assert {\"dik\", false} == HumanEval.candidate(\"dwik\", \"w\")\n    assert {\"\", true} == HumanEval.candidate(\"a\", \"a\")\n    assert {\"abcdedcba\", true} == HumanEval.candidate(\"abcdedcba\", \"\")\n    assert {\"abcdedcba\", true} == HumanEval.candidate(\"abcdedcba\", \"v\")\n    assert {\"abba\", true} == HumanEval.candidate(\"vabba\", \"v\")\n    assert {\"\", true} == HumanEval.candidate(\"mamma\", \"mia\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_113_odd_count", "language": "elixir", "prompt": "# Given a list of strings, where each string consists of only digits, return a list.\n# Each element i of the output should be \"the number of odd elements in the\n# string i of the input.\" where all the i's should be replaced by the number\n# of odd digits in the i'th string of the input.\n# >>> HumanEval.odd_count([\"1234567\"])\n# [\"the number of odd elements 4n the str4ng 4 of the 4nput.\"]\n# >>> HumanEval.odd_count([\"3\", \"11111111\"])\n# [\"the number of odd elements 1n the str1ng 1 of the 1nput.\", \"the number of odd elements 8n the str8ng 8 of the 8nput.\"]\n\ndefmodule HumanEval do\n  def candidate(lst), do: odd_count(lst)\n  def odd_count(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_113_odd_count.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'odd_count' do\n    assert [\"the number of odd elements 4n the str4ng 4 of the 4nput.\"] == HumanEval.candidate([\"1234567\"])\n    assert [\"the number of odd elements 1n the str1ng 1 of the 1nput.\", \"the number of odd elements 8n the str8ng 8 of the 8nput.\"] == HumanEval.candidate([\"3\", \"11111111\"])\n    assert [\"the number of odd elements 2n the str2ng 2 of the 2nput.\", \"the number of odd elements 3n the str3ng 3 of the 3nput.\", \"the number of odd elements 2n the str2ng 2 of the 2nput.\"] == HumanEval.candidate([\"271\", \"137\", \"314\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_114_minSubArraySum", "language": "elixir", "prompt": "# Given an array of integers nums, find the minimum sum of any non-empty sub-array\n# of nums.\n# Example\n# >>> HumanEval.minSubArraySum([2, 3, 4, 1, 2, 4])\n# 1\n# >>> HumanEval.minSubArraySum([-1, -2, -3])\n# -6\n\ndefmodule HumanEval do\n  def candidate(nums), do: minSubArraySum(nums)\n  def minSubArraySum(nums) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_114_minSubArraySum.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'minSubArraySum' do\n    assert 1 == HumanEval.candidate([2, 3, 4, 1, 2, 4])\n    assert -6 == HumanEval.candidate([-1, -2, -3])\n    assert -14 == HumanEval.candidate([-1, -2, -3, 2, -10])\n    assert -9999999999999999 == HumanEval.candidate([-9999999999999999])\n    assert 0 == HumanEval.candidate([0, 10, 20, 1000000])\n    assert -6 == HumanEval.candidate([-1, -2, -3, 10, -5])\n    assert -6 == HumanEval.candidate([100, -1, -2, -3, 10, -5])\n    assert 3 == HumanEval.candidate([10, 11, 13, 8, 3, 4])\n    assert -33 == HumanEval.candidate([100, -33, 32, -1, 0, -2])\n    assert -10 == HumanEval.candidate([-10])\n    assert 7 == HumanEval.candidate([7])\n    assert -1 == HumanEval.candidate([1, -1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_115_max_fill", "language": "elixir", "prompt": "# You are given a rectangular grid of wells. Each row represents a single well,\n# and each 1 in a row represents a single unit of water.\n# Each well has a corresponding bucket that can be used to extract water from it, \n# and all buckets have the same capacity.\n# Your task is to use the buckets to empty the wells.\n# Output the number of times you need to lower the buckets.\n# Example 1:\n# >>> HumanEval.max_fill([[0, 0, 1, 0], [0, 1, 0, 0], [1, 1, 1, 1]], 1)\n# 6\n# Example 2:\n# >>> HumanEval.max_fill([[0, 0, 1, 1], [0, 0, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1]], 2)\n# 5\n# Example 3:\n# >>> HumanEval.max_fill([[0, 0, 0], [0, 0, 0]], 5)\n# 0\n# Constraints:\n# * all wells have the same length\n# * 1 <= grid.length <= 10^2\n# * 1 <= grid[:,1].length <= 10^2\n# * grid[i][j] -> 0 | 1\n# * 1 <= capacity <= 10\n\ndefmodule HumanEval do\n  def candidate(grid, capacity), do: max_fill(grid, capacity)\n  def max_fill(grid, capacity) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_115_max_fill.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'max_fill' do\n    assert 6 == HumanEval.candidate([[0, 0, 1, 0], [0, 1, 0, 0], [1, 1, 1, 1]], 1)\n    assert 5 == HumanEval.candidate([[0, 0, 1, 1], [0, 0, 0, 0], [1, 1, 1, 1], [0, 1, 1, 1]], 2)\n    assert 0 == HumanEval.candidate([[0, 0, 0], [0, 0, 0]], 5)\n    assert 4 == HumanEval.candidate([[1, 1, 1, 1], [1, 1, 1, 1]], 2)\n    assert 2 == HumanEval.candidate([[1, 1, 1, 1], [1, 1, 1, 1]], 9)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_116_sort_array", "language": "elixir", "prompt": "# In this Kata, you have to sort an array of non-negative integers according to\n# number of ones in their binary representation in ascending order.\n# For similar number of ones, sort based on decimal value.\n# It must be implemented like this:\n# >>> HumanEval.sort_array([1, 5, 2, 3, 4])\n# [1, 2, 3, 4, 5]\n# >>> HumanEval.sort_array([-2, -3, -4, -5, -6])\n# [-6, -5, -4, -3, -2]\n# >>> HumanEval.sort_array([1, 0, 2, 3, 4])\n# [0, 1, 2, 3, 4]\n\ndefmodule HumanEval do\n  def candidate(arr), do: sort_array(arr)\n  def sort_array(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_116_sort_array.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sort_array' do\n    assert [1, 2, 4, 3, 5] == HumanEval.candidate([1, 5, 2, 3, 4])\n    assert [-4, -2, -6, -5, -3] == HumanEval.candidate([-2, -3, -4, -5, -6])\n    assert [0, 1, 2, 4, 3] == HumanEval.candidate([1, 0, 2, 3, 4])\n    assert [] == HumanEval.candidate([])\n    assert [2, 2, 4, 4, 3, 3, 5, 5, 5, 7, 77] == HumanEval.candidate([2, 5, 77, 4, 5, 3, 5, 7, 2, 3, 4])\n    assert [32, 3, 5, 6, 12, 44] == HumanEval.candidate([3, 6, 44, 12, 32, 5])\n    assert [2, 4, 8, 16, 32] == HumanEval.candidate([2, 4, 8, 16, 32])\n    assert [2, 4, 8, 16, 32] == HumanEval.candidate([2, 4, 8, 16, 32])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_117_select_words", "language": "elixir", "prompt": "# Given a string s and a natural number n, you have been tasked to implement \n# a function that returns a list of all words from string s that contain exactly \n# n consonants, in order these words appear in the string s.\n# If the string s is empty then the function should return an empty list.\n# Note: you may assume the input string contains only letters and spaces.\n# Examples:\n# >>> HumanEval.select_words(\"Mary had a little lamb\", 4)\n# [\"little\"]\n# >>> HumanEval.select_words(\"Mary had a little lamb\", 3)\n# [\"Mary\", \"lamb\"]\n# >>> HumanEval.select_words(\"simple white space\", 2)\n# []\n# >>> HumanEval.select_words(\"Hello world\", 4)\n# [\"world\"]\n# >>> HumanEval.select_words(\"Uncle sam\", 3)\n# [\"Uncle\"]\n\ndefmodule HumanEval do\n  def candidate(s, n), do: select_words(s, n)\n  def select_words(s, n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_117_select_words.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'select_words' do\n    assert [\"little\"] == HumanEval.candidate(\"Mary had a little lamb\", 4)\n    assert [\"Mary\", \"lamb\"] == HumanEval.candidate(\"Mary had a little lamb\", 3)\n    assert [] == HumanEval.candidate(\"simple white space\", 2)\n    assert [\"world\"] == HumanEval.candidate(\"Hello world\", 4)\n    assert [\"Uncle\"] == HumanEval.candidate(\"Uncle sam\", 3)\n    assert [] == HumanEval.candidate(\"\", 4)\n    assert [\"b\", \"c\", \"d\", \"f\"] == HumanEval.candidate(\"a b c d e f\", 1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_118_get_closest_vowel", "language": "elixir", "prompt": "# You are given a word. Your task is to find the closest vowel that stands between \n# two consonants from the right side of the word (case sensitive).\n# Vowels in the beginning and ending doesn't count. Return empty string if you didn't\n# find any vowel met the above condition. \n# You may assume that the given string contains English letter only.\n# Example:\n# >>> HumanEval.get_closest_vowel(\"yogurt\")\n# \"u\"\n# >>> HumanEval.get_closest_vowel(\"FULL\")\n# \"U\"\n# >>> HumanEval.get_closest_vowel(\"quick\")\n# \"\"\n# >>> HumanEval.get_closest_vowel(\"ab\")\n# \"\"\n\ndefmodule HumanEval do\n  def candidate(word), do: get_closest_vowel(word)\n  def get_closest_vowel(word) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_118_get_closest_vowel.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'get_closest_vowel' do\n    assert \"u\" == HumanEval.candidate(\"yogurt\")\n    assert \"u\" == HumanEval.candidate(\"full\")\n    assert \"\" == HumanEval.candidate(\"easy\")\n    assert \"\" == HumanEval.candidate(\"eAsy\")\n    assert \"\" == HumanEval.candidate(\"ali\")\n    assert \"a\" == HumanEval.candidate(\"bad\")\n    assert \"o\" == HumanEval.candidate(\"most\")\n    assert \"\" == HumanEval.candidate(\"ab\")\n    assert \"\" == HumanEval.candidate(\"ba\")\n    assert \"\" == HumanEval.candidate(\"quick\")\n    assert \"i\" == HumanEval.candidate(\"anime\")\n    assert \"\" == HumanEval.candidate(\"Asia\")\n    assert \"o\" == HumanEval.candidate(\"Above\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_119_match_parens", "language": "elixir", "prompt": "# You are given a list of two strings, both strings consist of open\n# parentheses '(' or close parentheses ')' only.\n# Your job is to check if it is possible to concatenate the two strings in\n# some order, that the resulting string will be good.\n# A string S is considered to be good if and only if all parentheses in S\n# are balanced. For example: the string '(())()' is good, while the string\n# '())' is not.\n# Return 'Yes' if there's a way to make a good string, and return 'No' otherwise.\n# Examples:\n# >>> HumanEval.match_parens([\"()(\", \")\"])\n# \"Yes\"\n# >>> HumanEval.match_parens([\")\", \")\"])\n# \"No\"\n\ndefmodule HumanEval do\n  def candidate(lst), do: match_parens(lst)\n  def match_parens(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_119_match_parens.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'match_parens' do\n    assert \"Yes\" == HumanEval.candidate([\"()(\", \")\"])\n    assert \"No\" == HumanEval.candidate([\")\", \")\"])\n    assert \"No\" == HumanEval.candidate([\"(()(())\", \"())())\"])\n    assert \"Yes\" == HumanEval.candidate([\")())\", \"(()()(\"])\n    assert \"Yes\" == HumanEval.candidate([\"(())))\", \"(()())((\"])\n    assert \"No\" == HumanEval.candidate([\"()\", \"())\"])\n    assert \"Yes\" == HumanEval.candidate([\"(()(\", \"()))()\"])\n    assert \"No\" == HumanEval.candidate([\"((((\", \"((())\"])\n    assert \"No\" == HumanEval.candidate([\")(()\", \"(()(\"])\n    assert \"No\" == HumanEval.candidate([\")(\", \")(\"])\n    assert \"Yes\" == HumanEval.candidate([\"(\", \")\"])\n    assert \"Yes\" == HumanEval.candidate([\")\", \"(\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_11_string_xor", "language": "elixir", "prompt": "# Input are two strings a and b consisting only of 1s and 0s.\n# Perform binary XOR on these inputs and return result also as a string.\n# >>> HumanEval.string_xor(\"010\", \"110\")\n# \"100\"\n\ndefmodule HumanEval do\n  def candidate(a, b), do: string_xor(a, b)\n  def string_xor(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_11_string_xor.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'string_xor' do\n    assert \"010010\" == HumanEval.candidate(\"111000\", \"101010\")\n    assert \"0\" == HumanEval.candidate(\"1\", \"1\")\n    assert \"0101\" == HumanEval.candidate(\"0101\", \"0000\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_120_maximum", "language": "elixir", "prompt": "# Given an array arr of integers and a positive integer k, return a sorted list \n# of length k with the maximum k numbers in arr.\n# Example 1:\n# >>> HumanEval.maximum([-3, -4, 5], 3)\n# [-4, -3, 5]\n# Example 2:\n# >>> HumanEval.maximum([4, -4, 4], 2)\n# [4, 4]\n# Example 3:\n# >>> HumanEval.maximum([-3, 2, 1, 2, -1, -2, 1], 1)\n# [2]\n# Note:\n# 1. The length of the array will be in the range of [1, 1000].\n# 2. The elements in the array will be in the range of [-1000, 1000].\n# 3. 0 <= k <= len(arr)\n\ndefmodule HumanEval do\n  def candidate(arr, k), do: maximum(arr, k)\n  def maximum(arr, k) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_120_maximum.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'maximum' do\n    assert [-4, -3, 5] == HumanEval.candidate([-3, -4, 5], 3)\n    assert [4, 4] == HumanEval.candidate([4, -4, 4], 2)\n    assert [2] == HumanEval.candidate([-3, 2, 1, 2, -1, -2, 1], 1)\n    assert [2, 20, 123] == HumanEval.candidate([123, -123, 20, 0, 1, 2, -3], 3)\n    assert [0, 1, 2, 20] == HumanEval.candidate([-123, 20, 0, 1, 2, -3], 4)\n    assert [-13, -8, 0, 0, 3, 5, 15] == HumanEval.candidate([5, 15, 0, 3, -13, -8, 0], 7)\n    assert [3, 5] == HumanEval.candidate([-1, 0, 2, 5, 3, -10], 2)\n    assert [5] == HumanEval.candidate([1, 0, 5, -7], 1)\n    assert [-4, 4] == HumanEval.candidate([4, -4], 2)\n    assert [-10, 10] == HumanEval.candidate([-10, 10], 2)\n    assert [] == HumanEval.candidate([1, 2, 3, -23, 243, -400, 0], 0)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_121_solution", "language": "elixir", "prompt": "# Given a non-empty list of integers, return the sum of all of the odd elements that are in even positions.\n# Examples\n# >>> HumanEval.solution([5, 8, 7, 1])\n# 12\n# >>> HumanEval.solution([3, 3, 3, 3, 3])\n# 9\n# >>> HumanEval.solution([30, 13, 24, 321])\n# 0\n\ndefmodule HumanEval do\n  def candidate(lst), do: solution(lst)\n  def solution(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_121_solution.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'solution' do\n    assert 12 == HumanEval.candidate([5, 8, 7, 1])\n    assert 9 == HumanEval.candidate([3, 3, 3, 3, 3])\n    assert 0 == HumanEval.candidate([30, 13, 24, 321])\n    assert 5 == HumanEval.candidate([5, 9])\n    assert 0 == HumanEval.candidate([2, 4, 8])\n    assert 23 == HumanEval.candidate([30, 13, 23, 32])\n    assert 3 == HumanEval.candidate([3, 13, 2, 9])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_122_add_elements", "language": "elixir", "prompt": "# Given a non-empty array of integers arr and an integer k, return\n# the sum of the elements with at most two digits from the first k elements of arr.\n# Example:\n# >>> HumanEval.add_elements([111, 21, 3, 4000, 5, 6, 7, 8, 9], 4)\n# 24\n# Constraints:\n# 1. 1 <= len(arr) <= 100\n# 2. 1 <= k <= len(arr)\n\ndefmodule HumanEval do\n  def candidate(arr, k), do: add_elements(arr, k)\n  def add_elements(arr, k) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_122_add_elements.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'add_elements' do\n    assert -4 == HumanEval.candidate([1, -2, -3, 41, 57, 76, 87, 88, 99], 3)\n    assert 0 == HumanEval.candidate([111, 121, 3, 4000, 5, 6], 2)\n    assert 125 == HumanEval.candidate([11, 21, 3, 90, 5, 6, 7, 8, 9], 4)\n    assert 24 == HumanEval.candidate([111, 21, 3, 4000, 5, 6, 7, 8, 9], 4)\n    assert 1 == HumanEval.candidate([1], 1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_123_get_odd_collatz", "language": "elixir", "prompt": "# Given a positive integer n, return a sorted list that has the odd numbers in collatz sequence.\n# The Collatz conjecture is a conjecture in mathematics that concerns a sequence defined\n# as follows: start with any positive integer n. Then each term is obtained from the \n# previous term as follows: if the previous term is even, the next term is one half of \n# the previous term. If the previous term is odd, the next term is 3 times the previous\n# term plus 1. The conjecture is that no matter what value of n, the sequence will always reach 1.\n# Note: \n# 1. Collatz(1) is [1].\n# 2. returned list sorted in increasing order.\n# For example:\n# get_odd_collatz(5) returns [1, 5] # The collatz sequence for 5 is [5, 16, 8, 4, 2, 1], so the odd numbers are only 1, and 5.\n# >>> HumanEval.get_odd_collatz(5)\n# [1, 5]\n\ndefmodule HumanEval do\n  def candidate(n), do: get_odd_collatz(n)\n  def get_odd_collatz(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_123_get_odd_collatz.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'get_odd_collatz' do\n    assert [1, 5, 7, 11, 13, 17] == HumanEval.candidate(14)\n    assert [1, 5] == HumanEval.candidate(5)\n    assert [1, 3, 5] == HumanEval.candidate(12)\n    assert [1] == HumanEval.candidate(1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_124_valid_date", "language": "elixir", "prompt": "# You have to write a function which validates a given date string and\n# returns True if the date is valid otherwise False.\n# The date is valid if all of the following rules are satisfied:\n# 1. The date string is not empty.\n# 2. The number of days is not less than 1 or higher than 31 days for months 1,3,5,7,8,10,12. And the number of days is not less than 1 or higher than 30 days for months 4,6,9,11. And, the number of days is not less than 1 or higher than 29 for the month 2.\n# 3. The months should not be less than 1 or higher than 12.\n# 4. The date should be in the format: mm-dd-yyyy\n# >>> HumanEval.valid_date(\"03-11-2000\")\n# true\n# >>> HumanEval.valid_date(\"15-01-2012\")\n# false\n# >>> HumanEval.valid_date(\"04-0-2040\")\n# false\n# >>> HumanEval.valid_date(\"06-04-2020\")\n# true\n# >>> HumanEval.valid_date(\"06/04/2020\")\n# false\n\ndefmodule HumanEval do\n  def candidate(date), do: valid_date(date)\n  def valid_date(date) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_124_valid_date.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'valid_date' do\n    assert true == HumanEval.candidate(\"03-11-2000\")\n    assert false == HumanEval.candidate(\"15-01-2012\")\n    assert false == HumanEval.candidate(\"04-0-2040\")\n    assert true == HumanEval.candidate(\"06-04-2020\")\n    assert true == HumanEval.candidate(\"01-01-2007\")\n    assert false == HumanEval.candidate(\"03-32-2011\")\n    assert false == HumanEval.candidate(\"\")\n    assert false == HumanEval.candidate(\"04-31-3000\")\n    assert true == HumanEval.candidate(\"06-06-2005\")\n    assert false == HumanEval.candidate(\"21-31-2000\")\n    assert true == HumanEval.candidate(\"04-12-2003\")\n    assert false == HumanEval.candidate(\"04122003\")\n    assert false == HumanEval.candidate(\"20030412\")\n    assert false == HumanEval.candidate(\"2003-04\")\n    assert false == HumanEval.candidate(\"2003-04-12\")\n    assert false == HumanEval.candidate(\"04-2003\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_125_split_words", "language": "elixir", "prompt": "# Given a string of words, return a list of words split on whitespace, if no whitespaces exists in the text you\n# should split on commas ',' if no commas exists you should return the number of lower-case letters with odd order in the\n# alphabet, ord('a') = 0, ord('b') = 1, ... ord('z') = 25\n# Examples\n# >>> HumanEval.split_words(\"Hello world!\")\n# [\"Hello\", \"world!\"]\n# >>> HumanEval.split_words(\"Hello,world!\")\n# [\"Hello\", \"world!\"]\n# >>> HumanEval.split_words(\"abcdef\")\n# 3\n\ndefmodule HumanEval do\n  def candidate(txt), do: split_words(txt)\n  def split_words(txt) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_125_split_words.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'split_words' do\n    assert [\"Hello\", \"world!\"] == HumanEval.candidate(\"Hello world!\")\n    assert [\"Hello\", \"world!\"] == HumanEval.candidate(\"Hello,world!\")\n    assert [\"Hello\", \"world,!\"] == HumanEval.candidate(\"Hello world,!\")\n    assert [\"Hello,Hello,world\", \"!\"] == HumanEval.candidate(\"Hello,Hello,world !\")\n    assert 3 == HumanEval.candidate(\"abcdef\")\n    assert 2 == HumanEval.candidate(\"aaabb\")\n    assert 1 == HumanEval.candidate(\"aaaBb\")\n    assert 0 == HumanEval.candidate(\"\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_126_is_sorted", "language": "elixir", "prompt": "# Given a list of numbers, return whether or not they are sorted\n# in ascending order. If list has more than 1 duplicate of the same\n# number, return False. Assume no negative numbers and only integers.\n# Examples\n# >>> HumanEval.is_sorted([5])\n# true\n# >>> HumanEval.is_sorted([1, 2, 3, 4, 5])\n# true\n# >>> HumanEval.is_sorted([1, 3, 2, 4, 5])\n# false\n# >>> HumanEval.is_sorted([1, 2, 3, 4, 5, 6])\n# true\n# >>> HumanEval.is_sorted([1, 2, 3, 4, 5, 6, 7])\n# true\n# >>> HumanEval.is_sorted([1, 3, 2, 4, 5, 6, 7])\n# false\n# >>> HumanEval.is_sorted([1, 2, 2, 3, 3, 4])\n# true\n# >>> HumanEval.is_sorted([1, 2, 2, 2, 3, 4])\n# false\n\ndefmodule HumanEval do\n  def candidate(lst), do: is_sorted(lst)\n  def is_sorted(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_126_is_sorted.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_sorted' do\n    assert true == HumanEval.candidate([5])\n    assert true == HumanEval.candidate([1, 2, 3, 4, 5])\n    assert false == HumanEval.candidate([1, 3, 2, 4, 5])\n    assert true == HumanEval.candidate([1, 2, 3, 4, 5, 6])\n    assert true == HumanEval.candidate([1, 2, 3, 4, 5, 6, 7])\n    assert false == HumanEval.candidate([1, 3, 2, 4, 5, 6, 7])\n    assert true == HumanEval.candidate([])\n    assert true == HumanEval.candidate([1])\n    assert false == HumanEval.candidate([3, 2, 1])\n    assert false == HumanEval.candidate([1, 2, 2, 2, 3, 4])\n    assert false == HumanEval.candidate([1, 2, 3, 3, 3, 4])\n    assert true == HumanEval.candidate([1, 2, 2, 3, 3, 4])\n    assert true == HumanEval.candidate([1, 2, 3, 4])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_127_intersection", "language": "elixir", "prompt": "# You are given two intervals,\n# where each interval is a pair of integers. For example, interval = (start, end) = (1, 2).\n# The given intervals are closed which means that the interval (start, end)\n# includes both start and end.\n# For each given interval, it is assumed that its start is less or equal its end.\n# Your task is to determine whether the length of intersection of these two \n# intervals is a prime number.\n# Example, the intersection of the intervals (1, 3), (2, 4) is (2, 3)\n# which its length is 1, which not a prime number.\n# If the length of the intersection is a prime number, return \"YES\",\n# otherwise, return \"NO\".\n# If the two intervals don't intersect, return \"NO\".\n# [input/output] samples:\n# >>> HumanEval.intersection({1, 2}, {2, 3})\n# \"NO\"\n# >>> HumanEval.intersection({-1, 1}, {0, 4})\n# \"NO\"\n# >>> HumanEval.intersection({-3, -1}, {-5, 5})\n# \"YES\"\n\ndefmodule HumanEval do\n  def candidate(interval1, interval2), do: intersection(interval1, interval2)\n  def intersection(interval1, interval2) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_127_intersection.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'intersection' do\n    assert \"NO\" == HumanEval.candidate({1, 2}, {2, 3})\n    assert \"NO\" == HumanEval.candidate({-1, 1}, {0, 4})\n    assert \"YES\" == HumanEval.candidate({-3, -1}, {-5, 5})\n    assert \"YES\" == HumanEval.candidate({-2, 2}, {-4, 0})\n    assert \"NO\" == HumanEval.candidate({-11, 2}, {-1, -1})\n    assert \"NO\" == HumanEval.candidate({1, 2}, {3, 5})\n    assert \"NO\" == HumanEval.candidate({1, 2}, {1, 2})\n    assert \"NO\" == HumanEval.candidate({-2, -2}, {-3, -2})\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_128_prod_signs", "language": "elixir", "prompt": "# You are given an array arr of integers and you need to return\n# sum of magnitudes of integers multiplied by product of all signs\n# of each number in the array, represented by 1, -1 or 0.\n# Note: return None for empty arr.\n# Example:\n# >>> HumanEval.prod_signs([1, 2, 2, -4])\n# 9\n# >>> HumanEval.prod_signs([0, 1])\n# 0\n# >>> HumanEval.prod_signs([])\n# nil\n\ndefmodule HumanEval do\n  def candidate(arr), do: prod_signs(arr)\n  def prod_signs(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_128_prod_signs.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'prod_signs' do\n    assert -9 == HumanEval.candidate([1, 2, 2, -4])\n    assert 0 == HumanEval.candidate([0, 1])\n    assert -10 == HumanEval.candidate([1, 1, 1, 2, 3, -1, 1])\n    assert nil == HumanEval.candidate([])\n    assert 20 == HumanEval.candidate([2, 4, 1, 2, -1, -1, 9])\n    assert 4 == HumanEval.candidate([-1, 1, -1, 1])\n    assert -4 == HumanEval.candidate([-1, 1, 1, 1])\n    assert 0 == HumanEval.candidate([-1, 1, 1, 0])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_129_minPath", "language": "elixir", "prompt": "# Given a grid with N rows and N columns (N >= 2) and a positive integer k, \n# each cell of the grid contains a value. Every integer in the range [1, N * N]\n# inclusive appears exactly once on the cells of the grid.\n# You have to find the minimum path of length k in the grid. You can start\n# from any cell, and in each step you can move to any of the neighbor cells,\n# in other words, you can go to cells which share an edge with you current\n# cell.\n# Please note that a path of length k means visiting exactly k cells (not\n# necessarily distinct).\n# You CANNOT go off the grid.\n# A path A (of length k) is considered less than a path B (of length k) if\n# after making the ordered lists of the values on the cells that A and B go\n# through (let's call them lst_A and lst_B), lst_A is lexicographically less\n# than lst_B, in other words, there exist an integer index i (1 <= i <= k)\n# such that lst_A[i] < lst_B[i] and for any j (1 <= j < i) we have\n# lst_A[j] = lst_B[j].\n# It is guaranteed that the answer is unique.\n# Return an ordered list of the values on the cells that the minimum path go through.\n# Examples:    \n# >>> HumanEval.minPath([[1, 2, 3], [4, 5, 6], [7, 8, 9]], 3)\n# [1, 2, 1]\n# >>> HumanEval.minPath([[5, 9, 3], [4, 1, 6], [7, 8, 2]], 1)\n# [1]\n\ndefmodule HumanEval do\n  def candidate(grid, k), do: minPath(grid, k)\n  def minPath(grid, k) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_129_minPath.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'minPath' do\n    assert [1, 2, 1] == HumanEval.candidate([[1, 2, 3], [4, 5, 6], [7, 8, 9]], 3)\n    assert [1] == HumanEval.candidate([[5, 9, 3], [4, 1, 6], [7, 8, 2]], 1)\n    assert [1, 2, 1, 2] == HumanEval.candidate([[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12], [13, 14, 15, 16]], 4)\n    assert [1, 10, 1, 10, 1, 10, 1] == HumanEval.candidate([[6, 4, 13, 10], [5, 7, 12, 1], [3, 16, 11, 15], [8, 14, 9, 2]], 7)\n    assert [1, 7, 1, 7, 1] == HumanEval.candidate([[8, 14, 9, 2], [6, 4, 13, 15], [5, 7, 1, 12], [3, 10, 11, 16]], 5)\n    assert [1, 6, 1, 6, 1, 6, 1, 6, 1] == HumanEval.candidate([[11, 8, 7, 2], [5, 16, 14, 4], [9, 3, 15, 6], [12, 13, 10, 1]], 9)\n    assert [1, 6, 1, 6, 1, 6, 1, 6, 1, 6, 1, 6] == HumanEval.candidate([[12, 13, 10, 1], [9, 3, 15, 6], [5, 16, 14, 4], [11, 8, 7, 2]], 12)\n    assert [1, 3, 1, 3, 1, 3, 1, 3] == HumanEval.candidate([[2, 7, 4], [3, 1, 5], [6, 8, 9]], 8)\n    assert [1, 5, 1, 5, 1, 5, 1, 5] == HumanEval.candidate([[6, 1, 5], [3, 8, 9], [2, 7, 4]], 8)\n    assert [1, 2, 1, 2, 1, 2, 1, 2, 1, 2] == HumanEval.candidate([[1, 2], [3, 4]], 10)\n    assert [1, 3, 1, 3, 1, 3, 1, 3, 1, 3] == HumanEval.candidate([[1, 3], [3, 2]], 10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_12_longest", "language": "elixir", "prompt": "# Out of list of strings, return the longest one. Return the first one in case of multiple\n# strings of the same length. Return None in case the input list is empty.\n# >>> HumanEval.longest([])\n# nil\n# >>> HumanEval.longest([\"a\", \"b\", \"c\"])\n# \"a\"\n# >>> HumanEval.longest([\"a\", \"bb\", \"ccc\"])\n# \"ccc\"\n\ndefmodule HumanEval do\n  def candidate(strings), do: longest(strings)\n  def longest(strings) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_12_longest.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'longest' do\n    assert nil == HumanEval.candidate([])\n    assert \"x\" == HumanEval.candidate([\"x\", \"y\", \"z\"])\n    assert \"zzzz\" == HumanEval.candidate([\"x\", \"yyy\", \"zzzz\", \"www\", \"kkkk\", \"abc\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_130_tri", "language": "elixir", "prompt": "# Everyone knows Fibonacci sequence, it was studied deeply by mathematicians in \n# the last couple centuries. However, what people don't know is Tribonacci sequence.\n# Tribonacci sequence is defined by the recurrence:\n# tri(1) = 3\n# tri(n) = 1 + n / 2, if n is even.\n# tri(n) =  tri(n - 1) + tri(n - 2) + tri(n + 1), if n is odd.\n# For example:\n# tri(2) = 1 + (2 / 2) = 2\n# tri(4) = 3\n# tri(3) = tri(2) + tri(1) + tri(4)\n# = 2 + 3 + 3 = 8 \n# You are given a non-negative integer number n, you have to a return a list of the \n# first n + 1 numbers of the Tribonacci sequence.\n# Examples:\n# >>> HumanEval.tri(3)\n# [1, 3, 2, 8]\n\ndefmodule HumanEval do\n  def candidate(n), do: tri(n)\n  def tri(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_130_tri.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'tri' do\n    assert [1, 3, 2, 8] == HumanEval.candidate(3)\n    assert [1, 3, 2, 8, 3] == HumanEval.candidate(4)\n    assert [1, 3, 2, 8, 3, 15] == HumanEval.candidate(5)\n    assert [1, 3, 2, 8, 3, 15, 4] == HumanEval.candidate(6)\n    assert [1, 3, 2, 8, 3, 15, 4, 24] == HumanEval.candidate(7)\n    assert [1, 3, 2, 8, 3, 15, 4, 24, 5] == HumanEval.candidate(8)\n    assert [1, 3, 2, 8, 3, 15, 4, 24, 5, 35] == HumanEval.candidate(9)\n    assert [1, 3, 2, 8, 3, 15, 4, 24, 5, 35, 6, 48, 7, 63, 8, 80, 9, 99, 10, 120, 11] == HumanEval.candidate(20)\n    assert [1] == HumanEval.candidate(0)\n    assert [1, 3] == HumanEval.candidate(1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_131_digits", "language": "elixir", "prompt": "# Given a positive integer n, return the product of the odd digits.\n# Return 0 if all digits are even.\n# For example:\n# >>> HumanEval.digits(1)\n# 1\n# >>> HumanEval.digits(4)\n# 0\n# >>> HumanEval.digits(235)\n# 15\n\ndefmodule HumanEval do\n  def candidate(n), do: digits(n)\n  def digits(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_131_digits.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'digits' do\n    assert 5 == HumanEval.candidate(5)\n    assert 5 == HumanEval.candidate(54)\n    assert 1 == HumanEval.candidate(120)\n    assert 5 == HumanEval.candidate(5014)\n    assert 315 == HumanEval.candidate(98765)\n    assert 2625 == HumanEval.candidate(5576543)\n    assert 0 == HumanEval.candidate(2468)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_132_is_nested", "language": "elixir", "prompt": "# Create a function that takes a string as input which contains only square brackets.\n# The function should return True if and only if there is a valid subsequence of brackets \n# where at least one bracket in the subsequence is nested.\n# >>> HumanEval.is_nested(\"[[]]\")\n# true\n# >>> HumanEval.is_nested(\"[]]]]]]][[[[[]\")\n# false\n# >>> HumanEval.is_nested(\"[][]\")\n# false\n# >>> HumanEval.is_nested(\"[]\")\n# false\n# >>> HumanEval.is_nested(\"[[][]]\")\n# true\n# >>> HumanEval.is_nested(\"[[]][[\")\n# true\n\ndefmodule HumanEval do\n  def candidate(string), do: is_nested(string)\n  def is_nested(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_132_is_nested.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_nested' do\n    assert true == HumanEval.candidate(\"[[]]\")\n    assert false == HumanEval.candidate(\"[]]]]]]][[[[[]\")\n    assert false == HumanEval.candidate(\"[][]\")\n    assert false == HumanEval.candidate(\"[]\")\n    assert true == HumanEval.candidate(\"[[[[]]]]\")\n    assert false == HumanEval.candidate(\"[]]]]]]]]]]\")\n    assert true == HumanEval.candidate(\"[][][[]]\")\n    assert false == HumanEval.candidate(\"[[]\")\n    assert false == HumanEval.candidate(\"[]]\")\n    assert true == HumanEval.candidate(\"[[]][[\")\n    assert true == HumanEval.candidate(\"[[][]]\")\n    assert false == HumanEval.candidate(\"\")\n    assert false == HumanEval.candidate(\"[[[[[[[[\")\n    assert false == HumanEval.candidate(\"]]]]]]]]\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_133_sum_squares", "language": "elixir", "prompt": "# You are given a list of numbers.\n# You need to return the sum of squared numbers in the given list,\n# round each element in the list to the upper int(Ceiling) first.\n# Examples:\n# >>> HumanEval.lst([1.0, 2.0, 3.0])\n# 14\n# >>> HumanEval.lst([1.0, 4.0, 9.0])\n# 98\n# >>> HumanEval.lst([1.0, 3.0, 5.0, 7.0])\n# 84\n# >>> HumanEval.lst([1.4, 4.2, 0.0])\n# 29\n# >>> HumanEval.lst([-2.4, 1.0, 1.0])\n# 6\n\ndefmodule HumanEval do\n  def candidate(lst), do: sum_squares(lst)\n  def sum_squares(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_133_sum_squares.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sum_squares' do\n    assert 14 == HumanEval.candidate([1.0, 2.0, 3.0])\n    assert 14 == HumanEval.candidate([1.0, 2.0, 3.0])\n    assert 84 == HumanEval.candidate([1.0, 3.0, 5.0, 7.0])\n    assert 29 == HumanEval.candidate([1.4, 4.2, 0.0])\n    assert 6 == HumanEval.candidate([-2.4, 1.0, 1.0])\n    assert 10230 == HumanEval.candidate([100.0, 1.0, 15.0, 2.0])\n    assert 200000000 == HumanEval.candidate([10000.0, 10000.0])\n    assert 75 == HumanEval.candidate([-1.4, 4.6, 6.3])\n    assert 1086 == HumanEval.candidate([-1.4, 17.9, 18.9, 19.9])\n    assert 0 == HumanEval.candidate([0.0])\n    assert 1 == HumanEval.candidate([-1.0])\n    assert 2 == HumanEval.candidate([-1.0, 1.0, 0.0])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_134_check_if_last_char_is_a_letter", "language": "elixir", "prompt": "# Create a function that returns True if the last character\n# of a given string is an alphabetical character and is not\n# a part of a word, and False otherwise.\n# Note: \"word\" is a group of characters separated by space.\n# Examples:\n# >>> HumanEval.check_if_last_char_is_a_letter(\"apple pie\")\n# false\n# >>> HumanEval.check_if_last_char_is_a_letter(\"apple pi e\")\n# true\n# >>> HumanEval.check_if_last_char_is_a_letter(\"apple pi e \")\n# false\n# >>> HumanEval.check_if_last_char_is_a_letter(\"\")\n# false\n\ndefmodule HumanEval do\n  def candidate(txt), do: check_if_last_char_is_a_letter(txt)\n  def check_if_last_char_is_a_letter(txt) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_134_check_if_last_char_is_a_letter.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'check_if_last_char_is_a_letter' do\n    assert false == HumanEval.candidate(\"apple\")\n    assert true == HumanEval.candidate(\"apple pi e\")\n    assert false == HumanEval.candidate(\"eeeee\")\n    assert true == HumanEval.candidate(\"A\")\n    assert false == HumanEval.candidate(\"Pumpkin pie \")\n    assert false == HumanEval.candidate(\"Pumpkin pie 1\")\n    assert false == HumanEval.candidate(\"\")\n    assert false == HumanEval.candidate(\"eeeee e \")\n    assert false == HumanEval.candidate(\"apple pie\")\n    assert false == HumanEval.candidate(\"apple pi e \")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_135_can_arrange", "language": "elixir", "prompt": "# Create a function which returns the largest index of an element which\n# is not greater than or equal to the element immediately preceding it. If\n# no such element exists then return -1. The given array will not contain\n# duplicate values.\n# Examples:\n# >>> HumanEval.can_arrange([1, 2, 4, 3, 5])\n# 3\n# >>> HumanEval.can_arrange([1, 2, 3])\n# -1\n\ndefmodule HumanEval do\n  def candidate(arr), do: can_arrange(arr)\n  def can_arrange(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_135_can_arrange.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'can_arrange' do\n    assert 3 == HumanEval.candidate([1, 2, 4, 3, 5])\n    assert -1 == HumanEval.candidate([1, 2, 4, 5])\n    assert 2 == HumanEval.candidate([1, 4, 2, 5, 6, 7, 8, 9, 10])\n    assert 4 == HumanEval.candidate([4, 8, 5, 7, 3])\n    assert -1 == HumanEval.candidate([])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_136_largest_smallest_integers", "language": "elixir", "prompt": "# Create a function that returns a tuple (a, b), where 'a' is\n# the largest of negative integers, and 'b' is the smallest\n# of positive integers in a list.\n# If there is no negative or positive integers, return them as None.\n# Examples:\n# >>> HumanEval.largest_smallest_integers([2, 4, 1, 3, 5, 7])\n# {nil, 1}\n# >>> HumanEval.largest_smallest_integers([])\n# {nil, nil}\n# >>> HumanEval.largest_smallest_integers([0])\n# {nil, nil}\n\ndefmodule HumanEval do\n  def candidate(lst), do: largest_smallest_integers(lst)\n  def largest_smallest_integers(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_136_largest_smallest_integers.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'largest_smallest_integers' do\n    assert {nil, 1} == HumanEval.candidate([2, 4, 1, 3, 5, 7])\n    assert {nil, 1} == HumanEval.candidate([2, 4, 1, 3, 5, 7, 0])\n    assert {-2, 1} == HumanEval.candidate([1, 3, 2, 4, 5, 6, -2])\n    assert {-7, 2} == HumanEval.candidate([4, 5, 3, 6, 2, 7, -7])\n    assert {-9, 2} == HumanEval.candidate([7, 3, 8, 4, 9, 2, 5, -9])\n    assert {nil, nil} == HumanEval.candidate([])\n    assert {nil, nil} == HumanEval.candidate([0])\n    assert {-1, nil} == HumanEval.candidate([-1, -3, -5, -6])\n    assert {-1, nil} == HumanEval.candidate([-1, -3, -5, -6, 0])\n    assert {-3, 1} == HumanEval.candidate([-6, -4, -4, -3, 1])\n    assert {-3, 1} == HumanEval.candidate([-6, -4, -4, -3, -100, 1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_137_compare_one", "language": "elixir", "prompt": "# Create a function that takes integers, floats, or strings representing\n# real numbers, and returns the larger variable in its given variable type.\n# Return None if the values are equal.\n# Note: If a real number is represented as a string, the floating point might be . or ,\n# >>> HumanEval.compare_one(1, 2.5)\n# 2.5\n# >>> HumanEval.compare_one(1, \"2,3\")\n# \"2,3\"\n# >>> HumanEval.compare_one(\"5,1\", \"6\")\n# \"6\"\n# >>> HumanEval.compare_one(\"1\", 1)\n# nil\n\ndefmodule HumanEval do\n  def candidate(a, b), do: compare_one(a, b)\n  def compare_one(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_137_compare_one.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'compare_one' do\n    assert 2 == HumanEval.candidate(1, 2)\n    assert 2.5 == HumanEval.candidate(1, 2.5)\n    assert 3 == HumanEval.candidate(2, 3)\n    assert 6 == HumanEval.candidate(5, 6)\n    assert \"2,3\" == HumanEval.candidate(1, \"2,3\")\n    assert \"6\" == HumanEval.candidate(\"5,1\", \"6\")\n    assert \"2\" == HumanEval.candidate(\"1\", \"2\")\n    assert nil == HumanEval.candidate(\"1\", 1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_138_is_equal_to_sum_even", "language": "elixir", "prompt": "# Evaluate whether the given number n can be written as the sum of exactly 4 positive even numbers\n# Example\n# >>> HumanEval.is_equal_to_sum_even(4)\n# false\n# >>> HumanEval.is_equal_to_sum_even(6)\n# false\n# >>> HumanEval.is_equal_to_sum_even(8)\n# true\n\ndefmodule HumanEval do\n  def candidate(n), do: is_equal_to_sum_even(n)\n  def is_equal_to_sum_even(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_138_is_equal_to_sum_even.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_equal_to_sum_even' do\n    assert false == HumanEval.candidate(4)\n    assert false == HumanEval.candidate(6)\n    assert true == HumanEval.candidate(8)\n    assert true == HumanEval.candidate(10)\n    assert false == HumanEval.candidate(11)\n    assert true == HumanEval.candidate(12)\n    assert false == HumanEval.candidate(13)\n    assert true == HumanEval.candidate(16)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_139_special_factorial", "language": "elixir", "prompt": "# The Brazilian factorial is defined as:\n# brazilian_factorial(n) = n! * (n-1)! * (n-2)! * ... * 1!\n# where n > 0\n# For example:\n# >>> HumanEval.special_factorial(4)\n# 288\n# The function will receive an integer as input and should return the special\n# factorial of this integer.\n\ndefmodule HumanEval do\n  def candidate(n), do: special_factorial(n)\n  def special_factorial(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_139_special_factorial.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'special_factorial' do\n    assert 288 == HumanEval.candidate(4)\n    assert 34560 == HumanEval.candidate(5)\n    assert 125411328000 == HumanEval.candidate(7)\n    assert 1 == HumanEval.candidate(1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_13_greatest_common_divisor", "language": "elixir", "prompt": "# Return a greatest common divisor of two integers a and b\n# >>> HumanEval.greatest_common_divisor(3, 5)\n# 1\n# >>> HumanEval.greatest_common_divisor(25, 15)\n# 5\n\ndefmodule HumanEval do\n  def candidate(a, b), do: greatest_common_divisor(a, b)\n  def greatest_common_divisor(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_13_greatest_common_divisor.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'greatest_common_divisor' do\n    assert 1 == HumanEval.candidate(3, 7)\n    assert 5 == HumanEval.candidate(10, 15)\n    assert 7 == HumanEval.candidate(49, 14)\n    assert 12 == HumanEval.candidate(144, 60)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_140_fix_spaces", "language": "elixir", "prompt": "# Given a string text, replace all spaces in it with underscores, \n# and if a string has more than 2 consecutive spaces, \n# then replace all consecutive spaces with - \n# >>> HumanEval.fix_spaces(\" Example\")\n# \"Example\"\n# >>> HumanEval.fix_spaces(\" Example 1\")\n# \"Example_1\"\n# >>> HumanEval.fix_spaces(\" Example 2\")\n# \"_Example_2\"\n# >>> HumanEval.fix_spaces(\" Example 3\")\n# \"_Example-3\"\n\ndefmodule HumanEval do\n  def candidate(text), do: fix_spaces(text)\n  def fix_spaces(text) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_140_fix_spaces.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fix_spaces' do\n    assert \"Example\" == HumanEval.candidate(\"Example\")\n    assert \"Mudasir_Hanif_\" == HumanEval.candidate(\"Mudasir Hanif \")\n    assert \"Yellow_Yellow__Dirty__Fellow\" == HumanEval.candidate(\"Yellow Yellow  Dirty  Fellow\")\n    assert \"Exa-mple\" == HumanEval.candidate(\"Exa   mple\")\n    assert \"-Exa_1_2_2_mple\" == HumanEval.candidate(\"   Exa 1 2 2 mple\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_141_file_name_check", "language": "elixir", "prompt": "# Create a function which takes a string representing a file's name, and returns\n# 'Yes' if the the file's name is valid, and returns 'No' otherwise.\n# A file's name is considered to be valid if and only if all the following conditions \n# are met:\n# - There should not be more than three digits ('0'-'9') in the file's name.\n# - The file's name contains exactly one dot '.'\n# - The substring before the dot should not be empty, and it starts with a letter from \n# the latin alphapet ('a'-'z' and 'A'-'Z').\n# - The substring after the dot should be one of these: ['txt', 'exe', 'dll']\n# Examples:\n# >>> HumanEval.file_name_check(\"example.txt\")\n# \"Yes\"\n# >>> HumanEval.file_name_check(\"1example.dll\")\n# \"No\"\n\ndefmodule HumanEval do\n  def candidate(file_name), do: file_name_check(file_name)\n  def file_name_check(file_name) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_141_file_name_check.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'file_name_check' do\n    assert \"Yes\" == HumanEval.candidate(\"example.txt\")\n    assert \"No\" == HumanEval.candidate(\"1example.dll\")\n    assert \"No\" == HumanEval.candidate(\"s1sdf3.asd\")\n    assert \"Yes\" == HumanEval.candidate(\"K.dll\")\n    assert \"Yes\" == HumanEval.candidate(\"MY16FILE3.exe\")\n    assert \"No\" == HumanEval.candidate(\"His12FILE94.exe\")\n    assert \"No\" == HumanEval.candidate(\"_Y.txt\")\n    assert \"No\" == HumanEval.candidate(\"?aREYA.exe\")\n    assert \"No\" == HumanEval.candidate(\"/this_is_valid.dll\")\n    assert \"No\" == HumanEval.candidate(\"this_is_valid.wow\")\n    assert \"Yes\" == HumanEval.candidate(\"this_is_valid.txt\")\n    assert \"No\" == HumanEval.candidate(\"this_is_valid.txtexe\")\n    assert \"No\" == HumanEval.candidate(\"#this2_i4s_5valid.ten\")\n    assert \"No\" == HumanEval.candidate(\"@this1_is6_valid.exe\")\n    assert \"No\" == HumanEval.candidate(\"this_is_12valid.6exe4.txt\")\n    assert \"No\" == HumanEval.candidate(\"all.exe.txt\")\n    assert \"Yes\" == HumanEval.candidate(\"I563_No.exe\")\n    assert \"Yes\" == HumanEval.candidate(\"Is3youfault.txt\")\n    assert \"Yes\" == HumanEval.candidate(\"no_one#knows.dll\")\n    assert \"No\" == HumanEval.candidate(\"1I563_Yes3.exe\")\n    assert \"No\" == HumanEval.candidate(\"I563_Yes3.txtt\")\n    assert \"No\" == HumanEval.candidate(\"final..txt\")\n    assert \"No\" == HumanEval.candidate(\"final132\")\n    assert \"No\" == HumanEval.candidate(\"_f4indsartal132.\")\n    assert \"No\" == HumanEval.candidate(\".txt\")\n    assert \"No\" == HumanEval.candidate(\"s.\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_142_sum_squares", "language": "elixir", "prompt": "# \"\n# This function will take a list of integers. For all entries in the list, the function shall square the integer entry if its index is a \n# multiple of 3 and will cube the integer entry if its index is a multiple of 4 and not a multiple of 3. The function will not \n# change the entries in the list whose indexes are not a multiple of 3 or 4. The function shall then return the sum of all entries. \n# Examples:\n# >>> lst\n# [1, 2, 3]\n# >>> lst\n# []\n# >>> lst\n# [-1, -5, 2, -1, -5]\n\ndefmodule HumanEval do\n  def candidate(lst), do: sum_squares(lst)\n  def sum_squares(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_142_sum_squares.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sum_squares' do\n    assert 6 == HumanEval.candidate([1, 2, 3])\n    assert 14 == HumanEval.candidate([1, 4, 9])\n    assert 0 == HumanEval.candidate([])\n    assert 9 == HumanEval.candidate([1, 1, 1, 1, 1, 1, 1, 1, 1])\n    assert -3 == HumanEval.candidate([-1, -1, -1, -1, -1, -1, -1, -1, -1])\n    assert 0 == HumanEval.candidate([0])\n    assert -126 == HumanEval.candidate([-1, -5, 2, -1, -5])\n    assert 3030 == HumanEval.candidate([-56, -99, 1, 0, -2])\n    assert 0 == HumanEval.candidate([-1, 0, 0, 0, 0, 0, 0, 0, -1])\n    assert -14196 == HumanEval.candidate([-16, -9, -2, 36, 36, 26, -20, 25, -40, 20, -4, 12, -26, 35, 37])\n    assert -1448 == HumanEval.candidate([-1, -3, 17, -1, -15, 13, -1, 14, -14, -12, -5, 14, -14, 6, 13, 11, 16, 16, 4, 10])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_143_words_in_sentence", "language": "elixir", "prompt": "# You are given a string representing a sentence,\n# the sentence contains some words separated by a space,\n# and you have to return a string that contains the words from the original sentence,\n# whose lengths are prime numbers,\n# the order of the words in the new string should be the same as the original one.\n# Example 1:\n# >>> HumanEval.words_in_sentence(\"This is a test\")\n# \"is\"\n# Example 2:\n# >>> HumanEval.words_in_sentence(\"lets go for swimming\")\n# \"go for\"\n# Constraints:\n# * 1 <= len(sentence) <= 100\n# * sentence contains only letters\n\ndefmodule HumanEval do\n  def candidate(sentence), do: words_in_sentence(sentence)\n  def words_in_sentence(sentence) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_143_words_in_sentence.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'words_in_sentence' do\n    assert \"is\" == HumanEval.candidate(\"This is a test\")\n    assert \"go for\" == HumanEval.candidate(\"lets go for swimming\")\n    assert \"there is no place\" == HumanEval.candidate(\"there is no place available here\")\n    assert \"Hi am Hussein\" == HumanEval.candidate(\"Hi I am Hussein\")\n    assert \"go for it\" == HumanEval.candidate(\"go for it\")\n    assert \"\" == HumanEval.candidate(\"here\")\n    assert \"is\" == HumanEval.candidate(\"here is\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_144_simplify", "language": "elixir", "prompt": "# Your task is to implement a function that will simplify the expression\n# x * n. The function returns True if x * n evaluates to a whole number and False\n# otherwise. Both x and n, are string representation of a fraction, and have the following format,\n# <numerator>/<denominator> where both numerator and denominator are positive whole numbers.\n# You can assume that x, and n are valid fractions, and do not have zero as denominator.\n# >>> HumanEval.simplify(\"1/5\", \"5/1\")\n# true\n# >>> HumanEval.simplify(\"1/6\", \"2/1\")\n# false\n# >>> HumanEval.simplify(\"7/10\", \"10/2\")\n# false\n\ndefmodule HumanEval do\n  def candidate(x, n), do: simplify(x, n)\n  def simplify(x, n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_144_simplify.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'simplify' do\n    assert true == HumanEval.candidate(\"1/5\", \"5/1\")\n    assert false == HumanEval.candidate(\"1/6\", \"2/1\")\n    assert true == HumanEval.candidate(\"5/1\", \"3/1\")\n    assert false == HumanEval.candidate(\"7/10\", \"10/2\")\n    assert true == HumanEval.candidate(\"2/10\", \"50/10\")\n    assert true == HumanEval.candidate(\"7/2\", \"4/2\")\n    assert true == HumanEval.candidate(\"11/6\", \"6/1\")\n    assert false == HumanEval.candidate(\"2/3\", \"5/2\")\n    assert false == HumanEval.candidate(\"5/2\", \"3/5\")\n    assert true == HumanEval.candidate(\"2/4\", \"8/4\")\n    assert true == HumanEval.candidate(\"2/4\", \"4/2\")\n    assert true == HumanEval.candidate(\"1/5\", \"5/1\")\n    assert false == HumanEval.candidate(\"1/5\", \"1/5\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_145_order_by_points", "language": "elixir", "prompt": "# Write a function which sorts the given list of integers\n# in ascending order according to the sum of their digits.\n# Note: if there are several items with similar sum of their digits,\n# order them based on their index in original list.\n# For example:\n# >>> HumanEval.order_by_points([1, 11, -1, -11, -12])\n# [-1, -11, 1, -12, 11]\n# >>> HumanEval.order_by_points([])\n# []\n\ndefmodule HumanEval do\n  def candidate(nums), do: order_by_points(nums)\n  def order_by_points(nums) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_145_order_by_points.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'order_by_points' do\n    assert [-1, -11, 1, -12, 11] == HumanEval.candidate([1, 11, -1, -11, -12])\n    assert [0, 2, 3, 6, 53, 423, 423, 423, 1234, 145, 37, 46, 56, 463, 3457] == HumanEval.candidate([1234, 423, 463, 145, 2, 423, 423, 53, 6, 37, 3457, 3, 56, 0, 46])\n    assert [] == HumanEval.candidate([])\n    assert [-3, -32, -98, -11, 1, 2, 43, 54] == HumanEval.candidate([1, -11, -32, 43, 54, -98, 2, -3])\n    assert [1, 10, 2, 11, 3, 4, 5, 6, 7, 8, 9] == HumanEval.candidate([1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11])\n    assert [-76, -21, 0, 4, 23, 6, 6] == HumanEval.candidate([0, 6, 6, -76, -21, 23, 4])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_146_specialFilter", "language": "elixir", "prompt": "# Write a function that takes an array of numbers as input and returns \n# the number of elements in the array that are greater than 10 and both \n# first and last digits of a number are odd (1, 3, 5, 7, 9).\n# For example:\n# >>> HumanEval.specialFilter([15, -73, 14, -15])\n# 1\n# >>> HumanEval.specialFilter([33, -2, -3, 45, 21, 109])\n# 2\n\ndefmodule HumanEval do\n  def candidate(nums), do: specialFilter(nums)\n  def specialFilter(nums) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_146_specialFilter.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'specialFilter' do\n    assert 0 == HumanEval.candidate([5, -2, 1, -5])\n    assert 1 == HumanEval.candidate([15, -73, 14, -15])\n    assert 2 == HumanEval.candidate([33, -2, -3, 45, 21, 109])\n    assert 4 == HumanEval.candidate([43, -12, 93, 125, 121, 109])\n    assert 3 == HumanEval.candidate([71, -2, -33, 75, 21, 19])\n    assert 0 == HumanEval.candidate([1])\n    assert 0 == HumanEval.candidate([])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_147_get_max_triples", "language": "elixir", "prompt": "# You are given a positive integer n. You have to create an integer array a of length n.\n# For each i (1 \u2264 i \u2264 n), the value of a[i] = i * i - i + 1.\n# Return the number of triples (a[i], a[j], a[k]) of a where i < j < k, \n# and a[i] + a[j] + a[k] is a multiple of 3.\n# Example :\n# >>> HumanEval.get_max_triples(5)\n# 1\n# Explanation: \n# a = [1, 3, 7, 13, 21]\n# The only valid triple is (1, 7, 13).\n\ndefmodule HumanEval do\n  def candidate(n), do: get_max_triples(n)\n  def get_max_triples(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_147_get_max_triples.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'get_max_triples' do\n    assert 1 == HumanEval.candidate(5)\n    assert 4 == HumanEval.candidate(6)\n    assert 36 == HumanEval.candidate(10)\n    assert 53361 == HumanEval.candidate(100)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_148_bf", "language": "elixir", "prompt": "# There are eight planets in our solar system: the closerst to the Sun \n# is Mercury, the next one is Venus, then Earth, Mars, Jupiter, Saturn, \n# Uranus, Neptune.\n# Write a function that takes two planet names as strings planet1 and planet2. \n# The function should return a tuple containing all planets whose orbits are \n# located between the orbit of planet1 and the orbit of planet2, sorted by \n# the proximity to the sun. \n# The function should return an empty tuple if planet1 or planet2\n# are not correct planet names. \n# Examples\n# >>> HumanEval.bf(\"Jupiter\", \"Neptune\")\n# {\"Saturn\", \"Uranus\"}\n# >>> HumanEval.bf(\"Earth\", \"Mercury\")\n# \"Venus\"\n# >>> HumanEval.bf(\"Mercury\", \"Uranus\")\n# {\"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\"}\n\ndefmodule HumanEval do\n  def candidate(planet1, planet2), do: bf(planet1, planet2)\n  def bf(planet1, planet2) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_148_bf.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'bf' do\n    assert {\"Saturn\", \"Uranus\"} == HumanEval.candidate(\"Jupiter\", \"Neptune\")\n    assert {\"Venus\"} == HumanEval.candidate(\"Earth\", \"Mercury\")\n    assert {\"Venus\", \"Earth\", \"Mars\", \"Jupiter\", \"Saturn\"} == HumanEval.candidate(\"Mercury\", \"Uranus\")\n    assert {\"Earth\", \"Mars\", \"Jupiter\", \"Saturn\", \"Uranus\"} == HumanEval.candidate(\"Neptune\", \"Venus\")\n    assert {} == HumanEval.candidate(\"Earth\", \"Earth\")\n    assert {} == HumanEval.candidate(\"Mars\", \"Earth\")\n    assert {} == HumanEval.candidate(\"Jupiter\", \"Makemake\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_149_sorted_list_sum", "language": "elixir", "prompt": "# Write a function that accepts a list of strings as a parameter,\n# deletes the strings that have odd lengths from it,\n# and returns the resulted list with a sorted order,\n# The list is always a list of strings and never an array of numbers,\n# and it may contain duplicates.\n# The order of the list should be ascending by length of each word, and you\n# should return the list sorted by that rule.\n# If two words have the same length, sort the list alphabetically.\n# The function should return a list of strings in sorted order.\n# You may assume that all words will have the same length.\n# For example:\n# >>> HumanEval.list_sort([\"aa\", \"a\", \"aaa\"])\n# [\"aa\"]\n# >>> HumanEval.list_sort([\"ab\", \"a\", \"aaa\", \"cd\"])\n# [\"ab\", \"cd\"]\n\ndefmodule HumanEval do\n  def candidate(lst), do: sorted_list_sum(lst)\n  def sorted_list_sum(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_149_sorted_list_sum.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sorted_list_sum' do\n    assert [\"aa\"] == HumanEval.candidate([\"aa\", \"a\", \"aaa\"])\n    assert [\"AI\", \"asdf\", \"school\"] == HumanEval.candidate([\"school\", \"AI\", \"asdf\", \"b\"])\n    assert [] == HumanEval.candidate([\"d\", \"b\", \"c\", \"a\"])\n    assert [\"abcd\", \"dcba\"] == HumanEval.candidate([\"d\", \"dcba\", \"abcd\", \"a\"])\n    assert [\"AI\", \"ai\", \"au\"] == HumanEval.candidate([\"AI\", \"ai\", \"au\"])\n    assert [] == HumanEval.candidate([\"a\", \"b\", \"b\", \"c\", \"c\", \"a\"])\n    assert [\"cc\", \"dd\", \"aaaa\", \"bbbb\"] == HumanEval.candidate([\"aaaa\", \"bbbb\", \"dd\", \"cc\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_14_all_prefixes", "language": "elixir", "prompt": "# Return list of all prefixes from shortest to longest of the input string\n# >>> HumanEval.all_prefixes(\"abc\")\n# [\"a\", \"ab\", \"abc\"]\n\ndefmodule HumanEval do\n  def candidate(string), do: all_prefixes(string)\n  def all_prefixes(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_14_all_prefixes.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'all_prefixes' do\n    assert [] == HumanEval.candidate(\"\")\n    assert [\"a\", \"as\", \"asd\", \"asdf\", \"asdfg\", \"asdfgh\"] == HumanEval.candidate(\"asdfgh\")\n    assert [\"W\", \"WW\", \"WWW\"] == HumanEval.candidate(\"WWW\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_150_x_or_y", "language": "elixir", "prompt": "# A simple program which should return the value of x if n is \n# a prime number and should return the value of y otherwise.\n# Examples:\n# >>> HumanEval.x_or_y(7, 34, 12)\n# 34\n# >>> HumanEval.x_or_y(15, 8, 5)\n# 5\n\ndefmodule HumanEval do\n  def candidate(n, x, y), do: x_or_y(n, x, y)\n  def x_or_y(n, x, y) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_150_x_or_y.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'x_or_y' do\n    assert 34 == HumanEval.candidate(7, 34, 12)\n    assert 5 == HumanEval.candidate(15, 8, 5)\n    assert 33 == HumanEval.candidate(3, 33, 5212)\n    assert 3 == HumanEval.candidate(1259, 3, 52)\n    assert -1 == HumanEval.candidate(7919, -1, 12)\n    assert 583 == HumanEval.candidate(3609, 1245, 583)\n    assert 129 == HumanEval.candidate(91, 56, 129)\n    assert 1234 == HumanEval.candidate(6, 34, 1234)\n    assert 0 == HumanEval.candidate(1, 2, 0)\n    assert 2 == HumanEval.candidate(2, 2, 0)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_151_double_the_difference", "language": "elixir", "prompt": "# Given a list of numbers, return the sum of squares of the numbers\n# in the list that are odd. Ignore numbers that are negative or not integers.\n# >>> HumanEval.double_the_difference([1, 3, 2, 0])\n# 10\n# >>> HumanEval.double_the_difference([-1, -2, 0])\n# 0\n# >>> HumanEval.double_the_difference([9, -2])\n# 81\n# >>> HumanEval.double_the_difference([0])\n# 0\n# If the input list is empty, return 0.\n\ndefmodule HumanEval do\n  def candidate(lst), do: double_the_difference(lst)\n  def double_the_difference(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_151_double_the_difference.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'double_the_difference' do\n    assert 0 == HumanEval.candidate([])\n    assert 25 == HumanEval.candidate([5.0, 4.0])\n    assert 0 == HumanEval.candidate([0.1, 0.2, 0.3])\n    assert 0 == HumanEval.candidate([-10.0, -20.0, -30.0])\n    assert 0 == HumanEval.candidate([-1.0, -2.0, 8.0])\n    assert 34 == HumanEval.candidate([0.2, 3.0, 5.0])\n    assert 165 == HumanEval.candidate([-9.0, -7.0, -5.0, -3.0, -1.0, 1.0, 3.0, 5.0, 7.0, 9.0])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_152_compare", "language": "elixir", "prompt": "# I think we all remember that feeling when the result of some long-awaited\n# event is finally known. The feelings and thoughts you have at that moment are\n# definitely worth noting down and comparing.\n# Your task is to determine if a person correctly guessed the results of a number of matches.\n# You are given two arrays of scores and guesses of equal length, where each index shows a match. \n# Return an array of the same length denoting how far off each guess was. If they have guessed correctly,\n# the value is 0, and if not, the value is the absolute difference between the guess and the score.\n# example:\n# >>> HumanEval.compare([1, 2, 3, 4, 5, 1], [1, 2, 3, 4, 2, -2])\n# [0, 0, 0, 0, 3, 3]\n# >>> HumanEval.compare([0, 5, 0, 0, 0, 4], [4, 1, 1, 0, 0, -2])\n# [4, 4, 1, 0, 0, 6]\n\ndefmodule HumanEval do\n  def candidate(game, guess), do: compare(game, guess)\n  def compare(game, guess) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_152_compare.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'compare' do\n    assert [0, 0, 0, 0, 3, 3] == HumanEval.candidate([1, 2, 3, 4, 5, 1], [1, 2, 3, 4, 2, -2])\n    assert [0, 0, 0, 0, 0, 0] == HumanEval.candidate([0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0])\n    assert [2, 4, 6] == HumanEval.candidate([1, 2, 3], [-1, -2, -3])\n    assert [2, 0, 0, 1] == HumanEval.candidate([1, 2, 3, 5], [-1, 2, 3, 4])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_153_Strongest_Extension", "language": "elixir", "prompt": "# You will be given the name of a class (a string) and a list of extensions.\n# The extensions are to be used to load additional classes to the class. The\n# strength of the extension is as follows: Let CAP be the number of the uppercase\n# letters in the extension's name, and let SM be the number of lowercase letters \n# in the extension's name, the strength is given by the fraction CAP - SM. \n# You should find the strongest extension and return a string in this \n# format: ClassName.StrongestExtensionName.\n# If there are two or more extensions with the same strength, you should\n# choose the one that comes first in the list.\n# For example, if you are given \"Slices\" as the class and a list of the\n# extensions: ['SErviNGSliCes', 'Cheese', 'StuFfed'] then you should\n# return 'Slices.SErviNGSliCes' since 'SErviNGSliCes' is the strongest extension \n# (its strength is -1).\n# Example:\n# >>> HumanEval.Strongest_Extension(\"my_class\", [\"AA\", \"Be\", \"CC\"])\n# \"my_class.AA\"\n\ndefmodule HumanEval do\n  def candidate(class_name, extensions), do: Strongest_Extension(class_name, extensions)\n  def Strongest_Extension(class_name, extensions) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_153_Strongest_Extension.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'Strongest_Extension' do\n    assert \"Watashi.eIGHt8OKe\" == HumanEval.candidate(\"Watashi\", [\"tEN\", \"niNE\", \"eIGHt8OKe\"])\n    assert \"Boku123.YEs.WeCaNe\" == HumanEval.candidate(\"Boku123\", [\"nani\", \"NazeDa\", \"YEs.WeCaNe\", \"32145tggg\"])\n    assert \"__YESIMHERE.NuLl__\" == HumanEval.candidate(\"__YESIMHERE\", [\"t\", \"eMptY\", \"nothing\", \"zeR00\", \"NuLl__\", \"123NoooneB321\"])\n    assert \"K.TAR\" == HumanEval.candidate(\"K\", [\"Ta\", \"TAR\", \"t234An\", \"cosSo\"])\n    assert \"__HAHA.123\" == HumanEval.candidate(\"__HAHA\", [\"Tab\", \"123\", \"781345\", \"-_-\"])\n    assert \"YameRore.okIWILL123\" == HumanEval.candidate(\"YameRore\", [\"HhAas\", \"okIWILL123\", \"WorkOut\", \"Fails\", \"-_-\"])\n    assert \"finNNalLLly.WoW\" == HumanEval.candidate(\"finNNalLLly\", [\"Die\", \"NowW\", \"Wow\", \"WoW\"])\n    assert \"_.Bb\" == HumanEval.candidate(\"_\", [\"Bb\", \"91245\"])\n    assert \"Sp.671235\" == HumanEval.candidate(\"Sp\", [\"671235\", \"Bb\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_154_cycpattern_check", "language": "elixir", "prompt": "# You are given 2 words. You need to return True if the second word or any of its rotations is a substring in the first word\n# >>> HumanEval.cycpattern_check(\"abcd\", \"abd\")\n# false\n# >>> HumanEval.cycpattern_check(\"hello\", \"ell\")\n# true\n# >>> HumanEval.cycpattern_check(\"whassup\", \"psus\")\n# false\n# >>> HumanEval.cycpattern_check(\"abab\", \"baa\")\n# true\n# >>> HumanEval.cycpattern_check(\"efef\", \"eeff\")\n# false\n# >>> HumanEval.cycpattern_check(\"himenss\", \"simen\")\n# true\n\ndefmodule HumanEval do\n  def candidate(a, b), do: cycpattern_check(a, b)\n  def cycpattern_check(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_154_cycpattern_check.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'cycpattern_check' do\n    assert false == HumanEval.candidate(\"xyzw\", \"xyw\")\n    assert true == HumanEval.candidate(\"yello\", \"ell\")\n    assert false == HumanEval.candidate(\"whattup\", \"ptut\")\n    assert true == HumanEval.candidate(\"efef\", \"fee\")\n    assert false == HumanEval.candidate(\"abab\", \"aabb\")\n    assert true == HumanEval.candidate(\"winemtt\", \"tinem\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_155_even_odd_count", "language": "elixir", "prompt": "# Given an integer. return a tuple that has the number of even and odd digits respectively.\n# Example:\n# >>> HumanEval.even_odd_count(-12)\n# {1, 1}\n# >>> HumanEval.even_odd_count(123)\n# {1, 2}\n\ndefmodule HumanEval do\n  def candidate(num), do: even_odd_count(num)\n  def even_odd_count(num) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_155_even_odd_count.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'even_odd_count' do\n    assert {0, 1} == HumanEval.candidate(7)\n    assert {1, 1} == HumanEval.candidate(-78)\n    assert {2, 2} == HumanEval.candidate(3452)\n    assert {3, 3} == HumanEval.candidate(346211)\n    assert {3, 3} == HumanEval.candidate(-345821)\n    assert {1, 0} == HumanEval.candidate(-2)\n    assert {2, 3} == HumanEval.candidate(-45347)\n    assert {1, 0} == HumanEval.candidate(0)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_156_int_to_mini_roman", "language": "elixir", "prompt": "# Given a positive integer, obtain its roman numeral equivalent as a string,\n# and return it in lowercase.\n# Restrictions: 1 <= num <= 1000\n# Examples:\n# >>> HumanEval.int_to_mini_roman(19)\n# \"xix\"\n# >>> HumanEval.int_to_mini_roman(152)\n# \"clii\"\n# >>> HumanEval.int_to_mini_roman(426)\n# \"cdxxvi\"\n\ndefmodule HumanEval do\n  def candidate(number), do: int_to_mini_roman(number)\n  def int_to_mini_roman(number) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_156_int_to_mini_roman.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'int_to_mini_roman' do\n    assert \"xix\" == HumanEval.candidate(19)\n    assert \"clii\" == HumanEval.candidate(152)\n    assert \"ccli\" == HumanEval.candidate(251)\n    assert \"cdxxvi\" == HumanEval.candidate(426)\n    assert \"d\" == HumanEval.candidate(500)\n    assert \"i\" == HumanEval.candidate(1)\n    assert \"iv\" == HumanEval.candidate(4)\n    assert \"xliii\" == HumanEval.candidate(43)\n    assert \"xc\" == HumanEval.candidate(90)\n    assert \"xciv\" == HumanEval.candidate(94)\n    assert \"dxxxii\" == HumanEval.candidate(532)\n    assert \"cm\" == HumanEval.candidate(900)\n    assert \"cmxciv\" == HumanEval.candidate(994)\n    assert \"m\" == HumanEval.candidate(1000)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_157_right_angle_triangle", "language": "elixir", "prompt": "# Given the lengths of the three sides of a triangle. Return True if the three\n# sides form a right-angled triangle, False otherwise.\n# A right-angled triangle is a triangle in which one angle is right angle or \n# 90 degree.\n# Example:\n# >>> HumanEval.right_angle_triangle(3, 4, 5)\n# true\n# >>> HumanEval.right_angle_triangle(1, 2, 3)\n# false\n\ndefmodule HumanEval do\n  def candidate(a, b, c), do: right_angle_triangle(a, b, c)\n  def right_angle_triangle(a, b, c) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_157_right_angle_triangle.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'right_angle_triangle' do\n    assert true == HumanEval.candidate(3, 4, 5)\n    assert false == HumanEval.candidate(1, 2, 3)\n    assert true == HumanEval.candidate(10, 6, 8)\n    assert false == HumanEval.candidate(2, 2, 2)\n    assert true == HumanEval.candidate(7, 24, 25)\n    assert false == HumanEval.candidate(10, 5, 7)\n    assert true == HumanEval.candidate(5, 12, 13)\n    assert true == HumanEval.candidate(15, 8, 17)\n    assert true == HumanEval.candidate(48, 55, 73)\n    assert false == HumanEval.candidate(1, 1, 1)\n    assert false == HumanEval.candidate(2, 2, 10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_158_find_max", "language": "elixir", "prompt": "# Write a function that accepts a list of strings.\n# The list contains different words. Return the word with maximum number\n# of unique characters. If multiple strings have maximum number of unique\n# characters, return the one which comes first in lexicographical order.\n# >>> HumanEval.find_max([\"name\", \"of\", \"string\"])\n# \"string\"\n# >>> HumanEval.find_max([\"name\", \"enam\", \"game\"])\n# \"enam\"\n# >>> HumanEval.find_max([\"aaaaaaa\", \"bb\", \"cc\"])\n# \"aaaaaaa\"\n\ndefmodule HumanEval do\n  def candidate(words), do: find_max(words)\n  def find_max(words) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_158_find_max.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'find_max' do\n    assert \"string\" == HumanEval.candidate([\"name\", \"of\", \"string\"])\n    assert \"enam\" == HumanEval.candidate([\"name\", \"enam\", \"game\"])\n    assert \"aaaaaaa\" == HumanEval.candidate([\"aaaaaaa\", \"bb\", \"cc\"])\n    assert \"abc\" == HumanEval.candidate([\"abc\", \"cba\"])\n    assert \"footbott\" == HumanEval.candidate([\"play\", \"this\", \"game\", \"of\", \"footbott\"])\n    assert \"gonna\" == HumanEval.candidate([\"we\", \"are\", \"gonna\", \"rock\"])\n    assert \"nation\" == HumanEval.candidate([\"we\", \"are\", \"a\", \"mad\", \"nation\"])\n    assert \"this\" == HumanEval.candidate([\"this\", \"is\", \"a\", \"prrk\"])\n    assert \"b\" == HumanEval.candidate([\"b\"])\n    assert \"play\" == HumanEval.candidate([\"play\", \"play\", \"play\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_159_eat", "language": "elixir", "prompt": "# You're a hungry rabbit, and you already have eaten a certain number of carrots,\n# but now you need to eat more carrots to complete the day's meals.\n# you should return an array of [ total number of eaten carrots after your meals,\n# the number of carrots left after your meals ]\n# if there are not enough remaining carrots, you will eat all remaining carrots, but will still be hungry.\n# Example:\n# >>> HumanEval.eat(5, 6, 10)\n# [11, 4]\n# >>> HumanEval.eat(4, 8, 9)\n# [12, 1]\n# >>> HumanEval.eat(1, 10, 10)\n# [11, 0]\n# >>> HumanEval.eat(2, 11, 5)\n# [7, 0]\n# Variables:\n# @number : integer\n# the number of carrots that you have eaten.\n# @need : integer\n# the number of carrots that you need to eat.\n# @remaining : integer\n# the number of remaining carrots thet exist in stock\n# Constrain:\n# * 0 <= number <= 1000\n# * 0 <= need <= 1000\n# * 0 <= remaining <= 1000\n# Have fun :)\n\ndefmodule HumanEval do\n  def candidate(number, need, remaining), do: eat(number, need, remaining)\n  def eat(number, need, remaining) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_159_eat.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'eat' do\n    assert [11, 4] == HumanEval.candidate(5, 6, 10)\n    assert [12, 1] == HumanEval.candidate(4, 8, 9)\n    assert [11, 0] == HumanEval.candidate(1, 10, 10)\n    assert [7, 0] == HumanEval.candidate(2, 11, 5)\n    assert [9, 2] == HumanEval.candidate(4, 5, 7)\n    assert [5, 0] == HumanEval.candidate(4, 5, 1)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_15_string_sequence", "language": "elixir", "prompt": "# Return a string containing space-delimited numbers starting from 0 upto n inclusive.\n# >>> HumanEval.string_sequence(0)\n# \"0\"\n# >>> HumanEval.string_sequence(5)\n# \"0 1 2 3 4 5\"\n\ndefmodule HumanEval do\n  def candidate(n), do: string_sequence(n)\n  def string_sequence(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_15_string_sequence.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'string_sequence' do\n    assert \"0\" == HumanEval.candidate(0)\n    assert \"0 1 2 3\" == HumanEval.candidate(3)\n    assert \"0 1 2 3 4 5 6 7 8 9 10\" == HumanEval.candidate(10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_160_do_algebra", "language": "elixir", "prompt": "# Given two lists operator, and operand. The first list has basic algebra operations, and \n# the second list is a list of integers. Use the two given lists to build the algebric \n# expression and return the evaluation of this expression.\n# The basic algebra operations:\n# Addition ( + ) \n# Subtraction ( - ) \n# Multiplication ( * ) \n# Floor division ( // ) \n# Exponentiation ( ** ) \n# Example:\n# operator['+', '*', '-']\n# array = [2, 3, 4, 5]\n# result = 2 + 3 * 4 - 5\n# => result = 9\n# Note:\n# The length of operator list is equal to the length of operand list minus one.\n# Operand is a list of of non-negative integers.\n# Operator list has at least one operator, and operand list has at least two operands.\n\ndefmodule HumanEval do\n  def candidate(operator, operand), do: do_algebra(operator, operand)\n  def do_algebra(operator, operand) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_160_do_algebra.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'do_algebra' do\n    assert 37 == HumanEval.candidate([\"**\", \"*\", \"+\"], [2, 3, 4, 5])\n    assert 9 == HumanEval.candidate([\"+\", \"*\", \"-\"], [2, 3, 4, 5])\n    assert 8 == HumanEval.candidate([\"//\", \"*\"], [7, 3, 4])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_161_solve", "language": "elixir", "prompt": "# You are given a string s.\n# if s[i] is a letter, reverse its case from lower to upper or vise versa, \n# otherwise keep it as it is.\n# If the string contains no letters, reverse the string.\n# The function should return the resulted string.\n# Examples\n# >>> HumanEval.solve(\"1234\")\n# \"4321\"\n# >>> HumanEval.solve(\"ab\")\n# \"AB\"\n# >>> HumanEval.solve(\"#a@C\")\n# \"#A@c\"\n\ndefmodule HumanEval do\n  def candidate(s), do: solve(s)\n  def solve(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_161_solve.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'solve' do\n    assert \"aSdF\" == HumanEval.candidate(\"AsDf\")\n    assert \"4321\" == HumanEval.candidate(\"1234\")\n    assert \"AB\" == HumanEval.candidate(\"ab\")\n    assert \"#A@c\" == HumanEval.candidate(\"#a@C\")\n    assert \"#aSDFw^45\" == HumanEval.candidate(\"#AsdfW^45\")\n    assert \"2@6#\" == HumanEval.candidate(\"#6@2\")\n    assert \"#$A^d\" == HumanEval.candidate(\"#$a^D\")\n    assert \"#CCC\" == HumanEval.candidate(\"#ccc\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_162_string_to_md5", "language": "elixir", "prompt": "# Given a string 'text', return its md5 hash equivalent string.\n# If 'text' is an empty string, return None.\n# >>> HumanEval.string_to_md5(\"Hello world\")\n# \"3e25960a79dbc69b674cd4ec67a72c62\"\n\ndefmodule HumanEval do\n  def candidate(text), do: string_to_md5(text)\n  def string_to_md5(text) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_162_string_to_md5.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'string_to_md5' do\n    assert \"3e25960a79dbc69b674cd4ec67a72c62\" == HumanEval.candidate(\"Hello world\")\n    assert nil == HumanEval.candidate(\"\")\n    assert \"0ef78513b0cb8cef12743f5aeb35f888\" == HumanEval.candidate(\"A B C\")\n    assert \"5f4dcc3b5aa765d61d8327deb882cf99\" == HumanEval.candidate(\"password\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_163_generate_integers", "language": "elixir", "prompt": "# Given two positive integers a and b, return the even digits between a\n# and b, in ascending order.\n# For example:\n# >>> HumanEval.generate_integers(2, 8)\n# [2, 4, 6, 8]\n# >>> HumanEval.generate_integers(8, 2)\n# [2, 4, 6, 8]\n# >>> HumanEval.generate_integers(10, 14)\n# []\n\ndefmodule HumanEval do\n  def candidate(a, b), do: generate_integers(a, b)\n  def generate_integers(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_163_generate_integers.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'generate_integers' do\n    assert [2, 4, 6, 8] == HumanEval.candidate(2, 10)\n    assert [2, 4, 6, 8] == HumanEval.candidate(10, 2)\n    assert [2, 4, 6, 8] == HumanEval.candidate(132, 2)\n    assert [] == HumanEval.candidate(17, 89)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_16_count_distinct_characters", "language": "elixir", "prompt": "# Given a string, find out how many distinct characters (regardless of case) does it consist of\n# >>> HumanEval.count_distinct_characters(\"xyzXYZ\")\n# 3\n# >>> HumanEval.count_distinct_characters(\"Jerry\")\n# 4\n\ndefmodule HumanEval do\n  def candidate(string), do: count_distinct_characters(string)\n  def count_distinct_characters(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_16_count_distinct_characters.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'count_distinct_characters' do\n    assert 0 == HumanEval.candidate(\"\")\n    assert 5 == HumanEval.candidate(\"abcde\")\n    assert 5 == HumanEval.candidate(\"abcdecadeCADE\")\n    assert 1 == HumanEval.candidate(\"aaaaAAAAaaaa\")\n    assert 5 == HumanEval.candidate(\"Jerry jERRY JeRRRY\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_17_parse_music", "language": "elixir", "prompt": "# Input to this function is a string representing musical notes in a special ASCII format.\n# Your task is to parse this string and return list of integers corresponding to how many beats does each\n# not last.\n# Here is a legend:\n# 'o' - whole note, lasts four beats\n# 'o|' - half note, lasts two beats\n# '.|' - quater note, lasts one beat\n# >>> HumanEval.parse_music(\"o o| .| o| o| .| .| .| .| o o\")\n# [4, 2, 1, 2, 2, 1, 1, 1, 1, 4, 4]\n\ndefmodule HumanEval do\n  def candidate(music_string), do: parse_music(music_string)\n  def parse_music(music_string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_17_parse_music.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'parse_music' do\n    assert [] == HumanEval.candidate(\"\")\n    assert [4, 4, 4, 4] == HumanEval.candidate(\"o o o o\")\n    assert [1, 1, 1, 1] == HumanEval.candidate(\".| .| .| .|\")\n    assert [2, 2, 1, 1, 4, 4, 4, 4] == HumanEval.candidate(\"o| o| .| .| o o o o\")\n    assert [2, 1, 2, 1, 4, 2, 4, 2] == HumanEval.candidate(\"o| .| o| .| o o| o o|\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_18_how_many_times", "language": "elixir", "prompt": "# Find how many times a given substring can be found in the original string. Count overlaping cases.\n# >>> HumanEval.how_many_times(\"\", \"a\")\n# 0\n# >>> HumanEval.how_many_times(\"aaa\", \"a\")\n# 3\n# >>> HumanEval.how_many_times(\"aaaa\", \"aa\")\n# 3\n\ndefmodule HumanEval do\n  def candidate(string, substring), do: how_many_times(string, substring)\n  def how_many_times(string, substring) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_18_how_many_times.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'how_many_times' do\n    assert 0 == HumanEval.candidate(\"\", \"x\")\n    assert 4 == HumanEval.candidate(\"xyxyxyx\", \"x\")\n    assert 4 == HumanEval.candidate(\"cacacacac\", \"cac\")\n    assert 1 == HumanEval.candidate(\"john doe\", \"john\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_19_sort_numbers", "language": "elixir", "prompt": "# Input is a space-delimited string of numberals from 'zero' to 'nine'.\n# Valid choices are 'zero', 'one', 'two', 'three', 'four', 'five', 'six', 'seven', 'eight' and 'nine'.\n# Return the string with numbers sorted from smallest to largest\n# >>> HumanEval.sort_numbers(\"three one five\")\n# \"one three five\"\n\ndefmodule HumanEval do\n  def candidate(numbers), do: sort_numbers(numbers)\n  def sort_numbers(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_19_sort_numbers.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sort_numbers' do\n    assert \"\" == HumanEval.candidate(\"\")\n    assert \"three\" == HumanEval.candidate(\"three\")\n    assert \"three five nine\" == HumanEval.candidate(\"three five nine\")\n    assert \"zero four five seven eight nine\" == HumanEval.candidate(\"five zero four seven nine eight\")\n    assert \"zero one two three four five six\" == HumanEval.candidate(\"six five four three two one zero\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_1_separate_paren_groups", "language": "elixir", "prompt": "# Input to this function is a string containing multiple groups of nested parentheses. Your goal is to\n# separate those group into separate strings and return the list of those.\n# Separate groups are balanced (each open brace is properly closed) and not nested within each other\n# Ignore any spaces in the input string.\n# >>> HumanEval.separate_paren_groups(\"( ) (( )) (( )( ))\")\n# [\"()\", \"(())\", \"(()())\"]\n\ndefmodule HumanEval do\n  def candidate(paren_string), do: separate_paren_groups(paren_string)\n  def separate_paren_groups(paren_string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_1_separate_paren_groups.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'separate_paren_groups' do\n    assert [\"(()())\", \"((()))\", \"()\", \"((())()())\"] == HumanEval.candidate(\"(()()) ((())) () ((())()())\")\n    assert [\"()\", \"(())\", \"((()))\", \"(((())))\"] == HumanEval.candidate(\"() (()) ((())) (((())))\")\n    assert [\"(()(())((())))\"] == HumanEval.candidate(\"(()(())((())))\")\n    assert [\"()\", \"(())\", \"(()())\"] == HumanEval.candidate(\"( ) (( )) (( )( ))\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_20_find_closest_elements", "language": "elixir", "prompt": "# From a supplied list of numbers (of length at least two) select and return two that are the closest to each\n# other and return them in order (smaller number, larger number).\n# >>> HumanEval.find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.2])\n# {2.0, 2.2}\n# >>> HumanEval.find_closest_elements([1.0, 2.0, 3.0, 4.0, 5.0, 2.0])\n# {2.0, 2.0}\n\ndefmodule HumanEval do\n  def candidate(numbers), do: find_closest_elements(numbers)\n  def find_closest_elements(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_20_find_closest_elements.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'find_closest_elements' do\n    assert {3.9, 4.0} == HumanEval.candidate([1.0, 2.0, 3.9, 4.0, 5.0, 2.2])\n    assert {5.0, 5.9} == HumanEval.candidate([1.0, 2.0, 5.9, 4.0, 5.0])\n    assert {2.0, 2.2} == HumanEval.candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.2])\n    assert {2.0, 2.0} == HumanEval.candidate([1.0, 2.0, 3.0, 4.0, 5.0, 2.0])\n    assert {2.2, 3.1} == HumanEval.candidate([1.1, 2.2, 3.1, 4.1, 5.1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_21_rescale_to_unit", "language": "elixir", "prompt": "# Given list of numbers (of at least two elements), apply a linear transform to that list,\n# such that the smallest number will become 0 and the largest will become 1\n# >>> HumanEval.rescale_to_unit([1.0, 2.0, 3.0, 4.0, 5.0])\n# [0.0, 0.25, 0.5, 0.75, 1.0]\n\ndefmodule HumanEval do\n  def candidate(numbers), do: rescale_to_unit(numbers)\n  def rescale_to_unit(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_21_rescale_to_unit.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'rescale_to_unit' do\n    assert [0.0, 1.0] == HumanEval.candidate([2.0, 49.9])\n    assert [1.0, 0.0] == HumanEval.candidate([100.0, 49.9])\n    assert [0.0, 0.25, 0.5, 0.75, 1.0] == HumanEval.candidate([1.0, 2.0, 3.0, 4.0, 5.0])\n    assert [0.25, 0.0, 1.0, 0.5, 0.75] == HumanEval.candidate([2.0, 1.0, 5.0, 3.0, 4.0])\n    assert [0.25, 0.0, 1.0, 0.5, 0.75] == HumanEval.candidate([12.0, 11.0, 15.0, 13.0, 14.0])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_22_filter_integers", "language": "elixir", "prompt": "# Filter given list of any python values only for integers\n# >>> HumanEval.filter_integers([\"a\", 3.14, 5])\n# [5]\n# >>> HumanEval.filter_integers([1, 2, 3, \"abc\", %{}, []])\n# [1, 2, 3]\n\ndefmodule HumanEval do\n  def candidate(values), do: filter_integers(values)\n  def filter_integers(values) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_22_filter_integers.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'filter_integers' do\n    assert [] == HumanEval.candidate([])\n    assert [4, 9] == HumanEval.candidate([4, %{}, [], 23.2, 9, \"adasd\"])\n    assert [3, 3, 3] == HumanEval.candidate([3, \"c\", 3, 3, \"a\", \"b\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_23_strlen", "language": "elixir", "prompt": "# Return length of given string\n# >>> HumanEval.strlen(\"\")\n# 0\n# >>> HumanEval.strlen(\"abc\")\n# 3\n\ndefmodule HumanEval do\n  def candidate(string), do: strlen(string)\n  def strlen(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_23_strlen.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'strlen' do\n    assert 0 == HumanEval.candidate(\"\")\n    assert 1 == HumanEval.candidate(\"x\")\n    assert 9 == HumanEval.candidate(\"asdasnakj\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_24_largest_divisor", "language": "elixir", "prompt": "# For a given number n, find the largest number that divides n evenly, smaller than n\n# >>> HumanEval.largest_divisor(15)\n# 5\n\ndefmodule HumanEval do\n  def candidate(n), do: largest_divisor(n)\n  def largest_divisor(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_24_largest_divisor.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'largest_divisor' do\n    assert 1 == HumanEval.candidate(3)\n    assert 1 == HumanEval.candidate(7)\n    assert 5 == HumanEval.candidate(10)\n    assert 50 == HumanEval.candidate(100)\n    assert 7 == HumanEval.candidate(49)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_25_factorize", "language": "elixir", "prompt": "# Return list of prime factors of given integer in the order from smallest to largest.\n# Each of the factors should be listed number of times corresponding to how many times it appeares in factorization.\n# Input number should be equal to the product of all factors\n# >>> HumanEval.factorize(8)\n# [2, 2, 2]\n# >>> HumanEval.factorize(25)\n# [5, 5]\n# >>> HumanEval.factorize(70)\n# [2, 5, 7]\n\ndefmodule HumanEval do\n  def candidate(n), do: factorize(n)\n  def factorize(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_25_factorize.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'factorize' do\n    assert [2] == HumanEval.candidate(2)\n    assert [2, 2] == HumanEval.candidate(4)\n    assert [2, 2, 2] == HumanEval.candidate(8)\n    assert [3, 19] == HumanEval.candidate(57)\n    assert [3, 3, 19, 19] == HumanEval.candidate(3249)\n    assert [3, 3, 3, 19, 19, 19] == HumanEval.candidate(185193)\n    assert [3, 19, 19, 19] == HumanEval.candidate(20577)\n    assert [2, 3, 3] == HumanEval.candidate(18)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_26_remove_duplicates", "language": "elixir", "prompt": "# From a list of integers, remove all elements that occur more than once.\n# Keep order of elements left the same as in the input.\n# >>> HumanEval.remove_duplicates([1, 2, 3, 2, 4])\n# [1, 3, 4]\n\ndefmodule HumanEval do\n  def candidate(numbers), do: remove_duplicates(numbers)\n  def remove_duplicates(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_26_remove_duplicates.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'remove_duplicates' do\n    assert [] == HumanEval.candidate([])\n    assert [1, 2, 3, 4] == HumanEval.candidate([1, 2, 3, 4])\n    assert [1, 4, 5] == HumanEval.candidate([1, 2, 3, 2, 4, 3, 5])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_27_flip_case", "language": "elixir", "prompt": "# For a given string, flip lowercase characters to uppercase and uppercase to lowercase.\n# >>> HumanEval.flip_case(\"Hello\")\n# \"hELLO\"\n\ndefmodule HumanEval do\n  def candidate(string), do: flip_case(string)\n  def flip_case(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_27_flip_case.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'flip_case' do\n    assert \"\" == HumanEval.candidate(\"\")\n    assert \"hELLO!\" == HumanEval.candidate(\"Hello!\")\n    assert \"tHESE VIOLENT DELIGHTS HAVE VIOLENT ENDS\" == HumanEval.candidate(\"These violent delights have violent ends\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_28_concatenate", "language": "elixir", "prompt": "# Concatenate list of strings into a single string\n# >>> HumanEval.concatenate([])\n# \"\"\n# >>> HumanEval.concatenate([\"a\", \"b\", \"c\"])\n# \"abc\"\n\ndefmodule HumanEval do\n  def candidate(strings), do: concatenate(strings)\n  def concatenate(strings) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_28_concatenate.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'concatenate' do\n    assert \"\" == HumanEval.candidate([])\n    assert \"xyz\" == HumanEval.candidate([\"x\", \"y\", \"z\"])\n    assert \"xyzwk\" == HumanEval.candidate([\"x\", \"y\", \"z\", \"w\", \"k\"])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_29_filter_by_prefix", "language": "elixir", "prompt": "# Filter an input list of strings only for ones that start with a given prefix.\n# >>> HumanEval.filter_by_prefix([], \"a\")\n# []\n# >>> HumanEval.filter_by_prefix([\"abc\", \"bcd\", \"cde\", \"array\"], \"a\")\n# [\"abc\", \"array\"]\n\ndefmodule HumanEval do\n  def candidate(strings, prefix), do: filter_by_prefix(strings, prefix)\n  def filter_by_prefix(strings, prefix) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_29_filter_by_prefix.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'filter_by_prefix' do\n    assert [] == HumanEval.candidate([], \"john\")\n    assert [\"xxx\", \"xxxAAA\", \"xxx\"] == HumanEval.candidate([\"xxx\", \"asd\", \"xxy\", \"john doe\", \"xxxAAA\", \"xxx\"], \"xxx\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_2_truncate_number", "language": "elixir", "prompt": "# Given a positive floating point number, it can be decomposed into\n# and integer part (largest integer smaller than given number) and decimals\n# (leftover part always smaller than 1).\n# Return the decimal part of the number.\n# >>> HumanEval.truncate_number(3.5)\n# 0.5\n\ndefmodule HumanEval do\n  def candidate(number), do: truncate_number(number)\n  def truncate_number(number) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_2_truncate_number.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'truncate_number' do\n    assert 0.5 == HumanEval.candidate(3.5)\n    assert 0.25 == HumanEval.candidate(1.25)\n    assert 0.0 == HumanEval.candidate(123.0)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_30_get_positive", "language": "elixir", "prompt": "# Return only positive numbers in the list.\n# >>> HumanEval.get_positive([-1, 2, -4, 5, 6])\n# [2, 5, 6]\n# >>> HumanEval.get_positive([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n# [5, 3, 2, 3, 9, 123, 1]\n\ndefmodule HumanEval do\n  def candidate(l), do: get_positive(l)\n  def get_positive(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_30_get_positive.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'get_positive' do\n    assert [4, 5, 6] == HumanEval.candidate([-1, -2, 4, 5, 6])\n    assert [5, 3, 2, 3, 3, 9, 123, 1] == HumanEval.candidate([5, 3, -5, 2, 3, 3, 9, 0, 123, 1, -10])\n    assert [] == HumanEval.candidate([-1, -2])\n    assert [] == HumanEval.candidate([])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_31_is_prime", "language": "elixir", "prompt": "# Return true if a given number is prime, and false otherwise.\n# >>> HumanEval.is_prime(6)\n# false\n# >>> HumanEval.is_prime(101)\n# true\n# >>> HumanEval.is_prime(11)\n# true\n# >>> HumanEval.is_prime(13441)\n# true\n# >>> HumanEval.is_prime(61)\n# true\n# >>> HumanEval.is_prime(4)\n# false\n# >>> HumanEval.is_prime(1)\n# false\n\ndefmodule HumanEval do\n  def candidate(n), do: is_prime(n)\n  def is_prime(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_31_is_prime.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_prime' do\n    assert false == HumanEval.candidate(6)\n    assert true == HumanEval.candidate(101)\n    assert true == HumanEval.candidate(11)\n    assert true == HumanEval.candidate(13441)\n    assert true == HumanEval.candidate(61)\n    assert false == HumanEval.candidate(4)\n    assert false == HumanEval.candidate(1)\n    assert true == HumanEval.candidate(5)\n    assert true == HumanEval.candidate(11)\n    assert true == HumanEval.candidate(17)\n    assert false == HumanEval.candidate(85)\n    assert false == HumanEval.candidate(77)\n    assert false == HumanEval.candidate(255379)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_33_sort_third", "language": "elixir", "prompt": "# This function takes a list l and returns a list l' such that\n# l' is identical to l in the indicies that are not divisible by three, while its values at the indicies that are divisible by three are equal\n# to the values of the corresponding indicies of l, but sorted.\n# >>> HumanEval.sort_third([1, 2, 3])\n# [1, 2, 3]\n# >>> HumanEval.sort_third([5, 6, 3, 4, 8, 9, 2])\n# [2, 6, 3, 4, 8, 9, 5]\n\ndefmodule HumanEval do\n  def candidate(l), do: sort_third(l)\n  def sort_third(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_33_sort_third.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sort_third' do\n    assert [2, 6, 3, 4, 8, 9, 5] == HumanEval.candidate([5, 6, 3, 4, 8, 9, 2])\n    assert [2, 8, 3, 4, 6, 9, 5] == HumanEval.candidate([5, 8, 3, 4, 6, 9, 2])\n    assert [2, 6, 9, 4, 8, 3, 5] == HumanEval.candidate([5, 6, 9, 4, 8, 3, 2])\n    assert [2, 6, 3, 4, 8, 9, 5, 1] == HumanEval.candidate([5, 6, 3, 4, 8, 9, 2, 1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_34_unique", "language": "elixir", "prompt": "# Return sorted unique elements in a list\n# >>> HumanEval.unique([5, 3, 5, 2, 3, 3, 9, 0, 123])\n# [0, 2, 3, 5, 9, 123]\n\ndefmodule HumanEval do\n  def candidate(l), do: unique(l)\n  def unique(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_34_unique.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'unique' do\n    assert [0, 2, 3, 5, 9, 123] == HumanEval.candidate([5, 3, 5, 2, 3, 3, 9, 0, 123])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_35_max_element", "language": "elixir", "prompt": "# Return maximum element in the list.\n# >>> HumanEval.max_element([1, 2, 3])\n# 3\n# >>> HumanEval.max_element([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n# 123\n\ndefmodule HumanEval do\n  def candidate(l), do: max_element(l)\n  def max_element(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_35_max_element.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'max_element' do\n    assert 3 == HumanEval.candidate([1, 2, 3])\n    assert 124 == HumanEval.candidate([5, 3, -5, 2, -3, 3, 9, 0, 124, 1, -10])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_36_fizz_buzz", "language": "elixir", "prompt": "# Return the number of times the digit 7 appears in integers less than n which are divisible by 11 or 13.\n# >>> HumanEval.fizz_buzz(50)\n# 0\n# >>> HumanEval.fizz_buzz(78)\n# 2\n# >>> HumanEval.fizz_buzz(79)\n# 3\n\ndefmodule HumanEval do\n  def candidate(n), do: fizz_buzz(n)\n  def fizz_buzz(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_36_fizz_buzz.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fizz_buzz' do\n    assert 0 == HumanEval.candidate(50)\n    assert 2 == HumanEval.candidate(78)\n    assert 3 == HumanEval.candidate(79)\n    assert 3 == HumanEval.candidate(100)\n    assert 6 == HumanEval.candidate(200)\n    assert 192 == HumanEval.candidate(4000)\n    assert 639 == HumanEval.candidate(10000)\n    assert 8026 == HumanEval.candidate(100000)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_37_sort_even", "language": "elixir", "prompt": "# This function takes a list l and returns a list l' such that\n# l' is identical to l in the odd indicies, while its values at the even indicies are equal\n# to the values of the even indicies of l, but sorted.\n# >>> HumanEval.sort_even([1, 2, 3])\n# [1, 2, 3]\n# >>> HumanEval.sort_even([5, 6, 3, 4])\n# [3, 6, 5, 4]\n\ndefmodule HumanEval do\n  def candidate(l), do: sort_even(l)\n  def sort_even(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_37_sort_even.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sort_even' do\n    assert [1, 2, 3] == HumanEval.candidate([1, 2, 3])\n    assert [-10, 3, -5, 2, -3, 3, 5, 0, 9, 1, 123] == HumanEval.candidate([5, 3, -5, 2, -3, 3, 9, 0, 123, 1, -10])\n    assert [-12, 8, 3, 4, 5, 2, 12, 11, 23, -10] == HumanEval.candidate([5, 8, -12, 4, 23, 2, 3, 11, 12, -10])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_39_prime_fib", "language": "elixir", "prompt": "# prime_fib returns n-th number that is a Fibonacci number and it's also prime.\n# >>> HumanEval.prime_fib(1)\n# 2\n# >>> HumanEval.prime_fib(2)\n# 3\n# >>> HumanEval.prime_fib(3)\n# 5\n# >>> HumanEval.prime_fib(4)\n# 13\n# >>> HumanEval.prime_fib(5)\n# 89\n\ndefmodule HumanEval do\n  def candidate(n), do: prime_fib(n)\n  def prime_fib(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_39_prime_fib.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'prime_fib' do\n    assert 2 == HumanEval.candidate(1)\n    assert 3 == HumanEval.candidate(2)\n    assert 5 == HumanEval.candidate(3)\n    assert 13 == HumanEval.candidate(4)\n    assert 89 == HumanEval.candidate(5)\n    assert 233 == HumanEval.candidate(6)\n    assert 1597 == HumanEval.candidate(7)\n    assert 28657 == HumanEval.candidate(8)\n    assert 514229 == HumanEval.candidate(9)\n    assert 433494437 == HumanEval.candidate(10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_3_below_zero", "language": "elixir", "prompt": "# You're given a list of deposit and withdrawal operations on a bank account that starts with\n# zero balance. Your task is to detect if at any point the balance of account fallls below zero, and\n# at that point function should return True. Otherwise it should return False.\n# >>> HumanEval.below_zero([1, 2, 3])\n# false\n# >>> HumanEval.below_zero([1, 2, -4, 5])\n# true\n\ndefmodule HumanEval do\n  def candidate(operations), do: below_zero(operations)\n  def below_zero(operations) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_3_below_zero.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'below_zero' do\n    assert false == HumanEval.candidate([])\n    assert false == HumanEval.candidate([1, 2, -3, 1, 2, -3])\n    assert true == HumanEval.candidate([1, 2, -4, 5, 6])\n    assert false == HumanEval.candidate([1, -1, 2, -2, 5, -5, 4, -4])\n    assert true == HumanEval.candidate([1, -1, 2, -2, 5, -5, 4, -5])\n    assert true == HumanEval.candidate([1, -2, 2, -2, 5, -5, 4, -4])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_40_triples_sum_to_zero", "language": "elixir", "prompt": "# triples_sum_to_zero takes a list of integers as an input.\n# it returns True if there are three distinct elements in the list that\n# sum to zero, and False otherwise.\n# >>> HumanEval.triples_sum_to_zero([1, 3, 5, 0])\n# false\n# >>> HumanEval.triples_sum_to_zero([1, 3, -2, 1])\n# true\n# >>> HumanEval.triples_sum_to_zero([1, 2, 3, 7])\n# false\n# >>> HumanEval.triples_sum_to_zero([2, 4, -5, 3, 9, 7])\n# true\n# >>> HumanEval.triples_sum_to_zero([1])\n# false\n\ndefmodule HumanEval do\n  def candidate(l), do: triples_sum_to_zero(l)\n  def triples_sum_to_zero(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_40_triples_sum_to_zero.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'triples_sum_to_zero' do\n    assert false == HumanEval.candidate([1, 3, 5, 0])\n    assert false == HumanEval.candidate([1, 3, 5, -1])\n    assert true == HumanEval.candidate([1, 3, -2, 1])\n    assert false == HumanEval.candidate([1, 2, 3, 7])\n    assert false == HumanEval.candidate([1, 2, 5, 7])\n    assert true == HumanEval.candidate([2, 4, -5, 3, 9, 7])\n    assert false == HumanEval.candidate([1])\n    assert false == HumanEval.candidate([1, 3, 5, -100])\n    assert false == HumanEval.candidate([100, 3, 5, -100])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_41_car_race_collision", "language": "elixir", "prompt": "# Imagine a road that's a perfectly straight infinitely long line.\n# n cars are driving left to right;  simultaneously, a different set of n cars\n# are driving right to left.   The two sets of cars start out being very far from\n# each other.  All cars move in the same speed.  Two cars are said to collide\n# when a car that's moving left to right hits a car that's moving right to left.\n# However, the cars are infinitely sturdy and strong; as a result, they continue moving\n# in their trajectory as if they did not collide.\n# This function outputs the number of such collisions.\n\ndefmodule HumanEval do\n  def candidate(n), do: car_race_collision(n)\n  def car_race_collision(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_41_car_race_collision.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'car_race_collision' do\n    assert 4 == HumanEval.candidate(2)\n    assert 9 == HumanEval.candidate(3)\n    assert 16 == HumanEval.candidate(4)\n    assert 64 == HumanEval.candidate(8)\n    assert 100 == HumanEval.candidate(10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_42_incr_list", "language": "elixir", "prompt": "# Return list with elements incremented by 1.\n# >>> HumanEval.incr_list([1, 2, 3])\n# [2, 3, 4]\n# >>> HumanEval.incr_list([5, 3, 5, 2, 3, 3, 9, 0, 123])\n# [6, 4, 6, 3, 4, 4, 10, 1, 124]\n\ndefmodule HumanEval do\n  def candidate(l), do: incr_list(l)\n  def incr_list(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_42_incr_list.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'incr_list' do\n    assert [] == HumanEval.candidate([])\n    assert [4, 3, 2] == HumanEval.candidate([3, 2, 1])\n    assert [6, 3, 6, 3, 4, 4, 10, 1, 124] == HumanEval.candidate([5, 2, 5, 2, 3, 3, 9, 0, 123])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_43_pairs_sum_to_zero", "language": "elixir", "prompt": "# pairs_sum_to_zero takes a list of integers as an input.\n# it returns True if there are two distinct elements in the list that\n# sum to zero, and False otherwise.\n# >>> HumanEval.pairs_sum_to_zero([1, 3, 5, 0])\n# false\n# >>> HumanEval.pairs_sum_to_zero([1, 3, -2, 1])\n# false\n# >>> HumanEval.pairs_sum_to_zero([1, 2, 3, 7])\n# false\n# >>> HumanEval.pairs_sum_to_zero([2, 4, -5, 3, 5, 7])\n# true\n# >>> HumanEval.pairs_sum_to_zero([1])\n# false\n\ndefmodule HumanEval do\n  def candidate(l), do: pairs_sum_to_zero(l)\n  def pairs_sum_to_zero(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_43_pairs_sum_to_zero.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'pairs_sum_to_zero' do\n    assert false == HumanEval.candidate([1, 3, 5, 0])\n    assert false == HumanEval.candidate([1, 3, -2, 1])\n    assert false == HumanEval.candidate([1, 2, 3, 7])\n    assert true == HumanEval.candidate([2, 4, -5, 3, 5, 7])\n    assert false == HumanEval.candidate([1])\n    assert true == HumanEval.candidate([-3, 9, -1, 3, 2, 30])\n    assert true == HumanEval.candidate([-3, 9, -1, 3, 2, 31])\n    assert false == HumanEval.candidate([-3, 9, -1, 4, 2, 30])\n    assert false == HumanEval.candidate([-3, 9, -1, 4, 2, 31])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_44_change_base", "language": "elixir", "prompt": "# Change numerical base of input number x to base.\n# return string representation after the conversion.\n# base numbers are less than 10.\n# >>> HumanEval.change_base(8, 3)\n# \"22\"\n# >>> HumanEval.change_base(8, 2)\n# \"1000\"\n# >>> HumanEval.change_base(7, 2)\n# \"111\"\n\ndefmodule HumanEval do\n  def candidate(x, base), do: change_base(x, base)\n  def change_base(x, base) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_44_change_base.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'change_base' do\n    assert \"22\" == HumanEval.candidate(8, 3)\n    assert \"100\" == HumanEval.candidate(9, 3)\n    assert \"11101010\" == HumanEval.candidate(234, 2)\n    assert \"10000\" == HumanEval.candidate(16, 2)\n    assert \"1000\" == HumanEval.candidate(8, 2)\n    assert \"111\" == HumanEval.candidate(7, 2)\n    assert \"2\" == HumanEval.candidate(2, 3)\n    assert \"3\" == HumanEval.candidate(3, 4)\n    assert \"4\" == HumanEval.candidate(4, 5)\n    assert \"5\" == HumanEval.candidate(5, 6)\n    assert \"6\" == HumanEval.candidate(6, 7)\n    assert \"7\" == HumanEval.candidate(7, 8)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_45_triangle_area", "language": "elixir", "prompt": "# Given length of a side and high return area for a triangle.\n# >>> HumanEval.triangle_area(5, 3)\n# 7.5\n\ndefmodule HumanEval do\n  def candidate(a, h), do: triangle_area(a, h)\n  def triangle_area(a, h) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_45_triangle_area.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'triangle_area' do\n    assert 7.5 == HumanEval.candidate(5, 3)\n    assert 2.0 == HumanEval.candidate(2, 2)\n    assert 40.0 == HumanEval.candidate(10, 8)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_46_fib4", "language": "elixir", "prompt": "# The Fib4 number sequence is a sequence similar to the Fibbonacci sequnece that's defined as follows:\n# fib4(0) -> 0\n# fib4(1) -> 0\n# fib4(2) -> 2\n# fib4(3) -> 0\n# fib4(n) -> fib4(n-1) + fib4(n-2) + fib4(n-3) + fib4(n-4).\n# Please write a function to efficiently compute the n-th element of the fib4 number sequence.  Do not use recursion.\n# >>> HumanEval.fib4(5)\n# 4\n# >>> HumanEval.fib4(6)\n# 8\n# >>> HumanEval.fib4(7)\n# 14\n\ndefmodule HumanEval do\n  def candidate(n), do: fib4(n)\n  def fib4(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_46_fib4.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fib4' do\n    assert 4 == HumanEval.candidate(5)\n    assert 28 == HumanEval.candidate(8)\n    assert 104 == HumanEval.candidate(10)\n    assert 386 == HumanEval.candidate(12)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_47_median", "language": "elixir", "prompt": "# Return median of elements in the list l.\n# >>> HumanEval.median([3, 1, 2, 4, 5])\n# 3\n# >>> HumanEval.median([-10, 4, 6, 1000, 10, 20])\n# 15.0\n\ndefmodule HumanEval do\n  def candidate(l), do: median(l)\n  def median(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_47_median.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'median' do\n    assert 3 == HumanEval.candidate([3, 1, 2, 4, 5])\n    assert 8.0 == HumanEval.candidate([-10, 4, 6, 1000, 10, 20])\n    assert 5 == HumanEval.candidate([5])\n    assert 5.5 == HumanEval.candidate([6, 5])\n    assert 7 == HumanEval.candidate([8, 1, 3, 9, 9, 2, 7])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_48_is_palindrome", "language": "elixir", "prompt": "# Checks if given string is a palindrome\n# >>> HumanEval.is_palindrome(\"\")\n# true\n# >>> HumanEval.is_palindrome(\"aba\")\n# true\n# >>> HumanEval.is_palindrome(\"aaaaa\")\n# true\n# >>> HumanEval.is_palindrome(\"zbcd\")\n# false\n\ndefmodule HumanEval do\n  def candidate(text), do: is_palindrome(text)\n  def is_palindrome(text) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_48_is_palindrome.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_palindrome' do\n    assert true == HumanEval.candidate(\"\")\n    assert true == HumanEval.candidate(\"aba\")\n    assert true == HumanEval.candidate(\"aaaaa\")\n    assert false == HumanEval.candidate(\"zbcd\")\n    assert true == HumanEval.candidate(\"xywyx\")\n    assert false == HumanEval.candidate(\"xywyz\")\n    assert false == HumanEval.candidate(\"xywzx\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_49_modp", "language": "elixir", "prompt": "# Return 2^n modulo p (be aware of numerics).\n# >>> HumanEval.modp(3, 5)\n# 3\n# >>> HumanEval.modp(1101, 101)\n# 2\n# >>> HumanEval.modp(0, 101)\n# 1\n# >>> HumanEval.modp(3, 11)\n# 8\n# >>> HumanEval.modp(100, 101)\n# 1\n\ndefmodule HumanEval do\n  def candidate(n, p), do: modp(n, p)\n  def modp(n, p) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_49_modp.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'modp' do\n    assert 3 == HumanEval.candidate(3, 5)\n    assert 2 == HumanEval.candidate(1101, 101)\n    assert 1 == HumanEval.candidate(0, 101)\n    assert 8 == HumanEval.candidate(3, 11)\n    assert 1 == HumanEval.candidate(100, 101)\n    assert 4 == HumanEval.candidate(30, 5)\n    assert 3 == HumanEval.candidate(31, 5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_4_mean_absolute_deviation", "language": "elixir", "prompt": "# For a given list of input numbers, calculate Mean Absolute Deviation\n# around the mean of this dataset.\n# Mean Absolute Deviation is the average absolute difference between each\n# element and a centerpoint (mean in this case):\n# MAD = average | x - x_mean |\n# >>> HumanEval.mean_absolute_deviation([1.0, 2.0, 3.0, 4.0])\n# 1.0\n\ndefmodule HumanEval do\n  def candidate(numbers), do: mean_absolute_deviation(numbers)\n  def mean_absolute_deviation(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_4_mean_absolute_deviation.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'mean_absolute_deviation' do\n    assert 0.5 == HumanEval.candidate([1.0, 2.0])\n    assert 1.0 == HumanEval.candidate([1.0, 2.0, 3.0, 4.0])\n    assert 1.2 == HumanEval.candidate([1.0, 2.0, 3.0, 4.0, 5.0])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_51_remove_vowels", "language": "elixir", "prompt": "# remove_vowels is a function that takes string and returns string without vowels.\n# >>> HumanEval.remove_vowels(\"\")\n# \"\"\n# >>> HumanEval.remove_vowels(\"abcdef\")\n# \"bcdf\"\n# >>> HumanEval.remove_vowels(\"aaaaa\")\n# \"\"\n# >>> HumanEval.remove_vowels(\"aaBAA\")\n# \"B\"\n# >>> HumanEval.remove_vowels(\"zbcd\")\n# \"zbcd\"\n\ndefmodule HumanEval do\n  def candidate(text), do: remove_vowels(text)\n  def remove_vowels(text) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_51_remove_vowels.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'remove_vowels' do\n    assert \"\" == HumanEval.candidate(\"\")\n    assert \"bcdf\nghjklm\" == HumanEval.candidate(\"abcdef\nghijklm\")\n    assert \"fdcb\" == HumanEval.candidate(\"fedcba\")\n    assert \"\" == HumanEval.candidate(\"eeeee\")\n    assert \"cB\" == HumanEval.candidate(\"acBAA\")\n    assert \"cB\" == HumanEval.candidate(\"EcBOO\")\n    assert \"ybcd\" == HumanEval.candidate(\"ybcd\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_52_below_threshold", "language": "elixir", "prompt": "# Return True if all numbers in the list l are below threshold t.\n# >>> HumanEval.below_threshold([1, 2, 4, 10], 100)\n# true\n# >>> HumanEval.below_threshold([1, 20, 4, 10], 5)\n# false\n\ndefmodule HumanEval do\n  def candidate(l, t), do: below_threshold(l, t)\n  def below_threshold(l, t) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_52_below_threshold.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'below_threshold' do\n    assert true == HumanEval.candidate([1, 2, 4, 10], 100)\n    assert false == HumanEval.candidate([1, 20, 4, 10], 5)\n    assert true == HumanEval.candidate([1, 20, 4, 10], 21)\n    assert true == HumanEval.candidate([1, 20, 4, 10], 22)\n    assert true == HumanEval.candidate([1, 8, 4, 10], 11)\n    assert false == HumanEval.candidate([1, 8, 4, 10], 10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_53_add", "language": "elixir", "prompt": "# Add two numbers x and y\n# >>> HumanEval.add(2, 3)\n# 5\n# >>> HumanEval.add(5, 7)\n# 12\n\ndefmodule HumanEval do\n  def candidate(x, y), do: add(x, y)\n  def add(x, y) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_53_add.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'add' do\n    assert 1 == HumanEval.candidate(0, 1)\n    assert 1 == HumanEval.candidate(1, 0)\n    assert 5 == HumanEval.candidate(2, 3)\n    assert 12 == HumanEval.candidate(5, 7)\n    assert 12 == HumanEval.candidate(7, 5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_54_same_chars", "language": "elixir", "prompt": "# Check if two words have the same characters.\n# >>> HumanEval.same_chars(\"eabcdzzzz\", \"dddzzzzzzzddeddabc\")\n# true\n# >>> HumanEval.same_chars(\"abcd\", \"dddddddabc\")\n# true\n# >>> HumanEval.same_chars(\"dddddddabc\", \"abcd\")\n# true\n# >>> HumanEval.same_chars(\"eabcd\", \"dddddddabc\")\n# false\n# >>> HumanEval.same_chars(\"abcd\", \"dddddddabce\")\n# false\n# >>> HumanEval.same_chars(\"eabcdzzzz\", \"dddzzzzzzzddddabc\")\n# false\n\ndefmodule HumanEval do\n  def candidate(s0, s1), do: same_chars(s0, s1)\n  def same_chars(s0, s1) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_54_same_chars.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'same_chars' do\n    assert true == HumanEval.candidate(\"eabcdzzzz\", \"dddzzzzzzzddeddabc\")\n    assert true == HumanEval.candidate(\"abcd\", \"dddddddabc\")\n    assert true == HumanEval.candidate(\"dddddddabc\", \"abcd\")\n    assert false == HumanEval.candidate(\"eabcd\", \"dddddddabc\")\n    assert false == HumanEval.candidate(\"abcd\", \"dddddddabcf\")\n    assert false == HumanEval.candidate(\"eabcdzzzz\", \"dddzzzzzzzddddabc\")\n    assert false == HumanEval.candidate(\"aabb\", \"aaccc\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_55_fib", "language": "elixir", "prompt": "# Return n-th Fibonacci number.\n# >>> HumanEval.fib(10)\n# 55\n# >>> HumanEval.fib(1)\n# 1\n# >>> HumanEval.fib(8)\n# 21\n\ndefmodule HumanEval do\n  def candidate(n), do: fib(n)\n  def fib(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_55_fib.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fib' do\n    assert 55 == HumanEval.candidate(10)\n    assert 1 == HumanEval.candidate(1)\n    assert 21 == HumanEval.candidate(8)\n    assert 89 == HumanEval.candidate(11)\n    assert 144 == HumanEval.candidate(12)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_56_correct_bracketing", "language": "elixir", "prompt": "# brackets is a string of \"<\" and \">\".\n# return True if every opening bracket has a corresponding closing bracket.\n# >>> HumanEval.correct_bracketing(\"<\")\n# false\n# >>> HumanEval.correct_bracketing(\"<>\")\n# true\n# >>> HumanEval.correct_bracketing(\"<<><>>\")\n# true\n# >>> HumanEval.correct_bracketing(\"><<>\")\n# false\n\ndefmodule HumanEval do\n  def candidate(brackets), do: correct_bracketing(brackets)\n  def correct_bracketing(brackets) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_56_correct_bracketing.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'correct_bracketing' do\n    assert true == HumanEval.candidate(\"<>\")\n    assert true == HumanEval.candidate(\"<<><>>\")\n    assert true == HumanEval.candidate(\"<><><<><>><>\")\n    assert true == HumanEval.candidate(\"<><><<<><><>><>><<><><<>>>\")\n    assert false == HumanEval.candidate(\"<<<><>>>>\")\n    assert false == HumanEval.candidate(\"><<>\")\n    assert false == HumanEval.candidate(\"<\")\n    assert false == HumanEval.candidate(\"<<<<\")\n    assert false == HumanEval.candidate(\">\")\n    assert false == HumanEval.candidate(\"<<>\")\n    assert false == HumanEval.candidate(\"<><><<><>><>><<>\")\n    assert false == HumanEval.candidate(\"<><><<><>><>>><>\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_57_monotonic", "language": "elixir", "prompt": "# Return True is list elements are monotonically increasing or decreasing.\n# >>> HumanEval.monotonic([1, 2, 4, 20])\n# true\n# >>> HumanEval.monotonic([1, 20, 4, 10])\n# false\n# >>> HumanEval.monotonic([4, 1, 0, -10])\n# true\n\ndefmodule HumanEval do\n  def candidate(l), do: monotonic(l)\n  def monotonic(l) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_57_monotonic.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'monotonic' do\n    assert true == HumanEval.candidate([1, 2, 4, 10])\n    assert true == HumanEval.candidate([1, 2, 4, 20])\n    assert false == HumanEval.candidate([1, 20, 4, 10])\n    assert true == HumanEval.candidate([4, 1, 0, -10])\n    assert true == HumanEval.candidate([4, 1, 1, 0])\n    assert false == HumanEval.candidate([1, 2, 3, 2, 5, 60])\n    assert true == HumanEval.candidate([1, 2, 3, 4, 5, 60])\n    assert true == HumanEval.candidate([9, 9, 9, 9])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_58_common", "language": "elixir", "prompt": "# Return sorted unique common elements for two lists.\n# >>> HumanEval.common([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n# [1, 5, 653]\n# >>> HumanEval.common([5, 3, 2, 8], [3, 2])\n# [2, 3]\n\ndefmodule HumanEval do\n  def candidate(l1, l2), do: common(l1, l2)\n  def common(l1, l2) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_58_common.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'common' do\n    assert [1, 5, 653] == HumanEval.candidate([1, 4, 3, 34, 653, 2, 5], [5, 7, 1, 5, 9, 653, 121])\n    assert [2, 3] == HumanEval.candidate([5, 3, 2, 8], [3, 2])\n    assert [2, 3, 4] == HumanEval.candidate([4, 3, 2, 8], [3, 2, 4])\n    assert [] == HumanEval.candidate([4, 3, 2, 8], [])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_59_largest_prime_factor", "language": "elixir", "prompt": "# Return the largest prime factor of n. Assume n > 1 and is not a prime.\n# >>> HumanEval.largest_prime_factor(13195)\n# 29\n# >>> HumanEval.largest_prime_factor(2048)\n# 2\n\ndefmodule HumanEval do\n  def candidate(n), do: largest_prime_factor(n)\n  def largest_prime_factor(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_59_largest_prime_factor.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'largest_prime_factor' do\n    assert 5 == HumanEval.candidate(15)\n    assert 3 == HumanEval.candidate(27)\n    assert 7 == HumanEval.candidate(63)\n    assert 11 == HumanEval.candidate(330)\n    assert 29 == HumanEval.candidate(13195)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_5_intersperse", "language": "elixir", "prompt": "# Insert a number 'delimeter' between every two consecutive elements of input list `numbers'\n# >>> HumanEval.intersperse([], 4)\n# []\n# >>> HumanEval.intersperse([1, 2, 3], 4)\n# [1, 4, 2, 4, 3]\n\ndefmodule HumanEval do\n  def candidate(numbers, delimeter), do: intersperse(numbers, delimeter)\n  def intersperse(numbers, delimeter) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_5_intersperse.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'intersperse' do\n    assert [] == HumanEval.candidate([], 7)\n    assert [5, 8, 6, 8, 3, 8, 2] == HumanEval.candidate([5, 6, 3, 2], 8)\n    assert [2, 2, 2, 2, 2] == HumanEval.candidate([2, 2, 2], 2)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_60_sum_to_n", "language": "elixir", "prompt": "# sum_to_n is a function that sums numbers from 1 to n.\n# >>> HumanEval.sum_to_n(30)\n# 465\n# >>> HumanEval.sum_to_n(100)\n# 5050\n# >>> HumanEval.sum_to_n(5)\n# 15\n# >>> HumanEval.sum_to_n(10)\n# 55\n# >>> HumanEval.sum_to_n(1)\n# 1\n\ndefmodule HumanEval do\n  def candidate(n), do: sum_to_n(n)\n  def sum_to_n(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_60_sum_to_n.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sum_to_n' do\n    assert 1 == HumanEval.candidate(1)\n    assert 21 == HumanEval.candidate(6)\n    assert 66 == HumanEval.candidate(11)\n    assert 465 == HumanEval.candidate(30)\n    assert 5050 == HumanEval.candidate(100)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_61_correct_bracketing", "language": "elixir", "prompt": "# brackets is a string of \"(\" and \")\".\n# return True if every opening bracket has a corresponding closing bracket.\n# >>> HumanEval.correct_bracketing(\"(\")\n# false\n# >>> HumanEval.correct_bracketing(\"()\")\n# true\n# >>> HumanEval.correct_bracketing(\"(()())\")\n# true\n# >>> HumanEval.correct_bracketing(\")(()\")\n# false\n\ndefmodule HumanEval do\n  def candidate(brackets), do: correct_bracketing(brackets)\n  def correct_bracketing(brackets) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_61_correct_bracketing.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'correct_bracketing' do\n    assert true == HumanEval.candidate(\"()\")\n    assert true == HumanEval.candidate(\"(()())\")\n    assert true == HumanEval.candidate(\"()()(()())()\")\n    assert true == HumanEval.candidate(\"()()((()()())())(()()(()))\")\n    assert false == HumanEval.candidate(\"((()())))\")\n    assert false == HumanEval.candidate(\")(()\")\n    assert false == HumanEval.candidate(\"(\")\n    assert false == HumanEval.candidate(\"((((\")\n    assert false == HumanEval.candidate(\")\")\n    assert false == HumanEval.candidate(\"(()\")\n    assert false == HumanEval.candidate(\"()()(()())())(()\")\n    assert false == HumanEval.candidate(\"()()(()())()))()\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_62_derivative", "language": "elixir", "prompt": "# xs represent coefficients of a polynomial.\n# xs[0] + xs[1] * x + xs[2] * x^2 + ....\n# Return derivative of this polynomial in the same form.\n# >>> HumanEval.derivative([3, 1, 2, 4, 5])\n# [1, 4, 12, 20]\n# >>> HumanEval.derivative([1, 2, 3])\n# [2, 6]\n\ndefmodule HumanEval do\n  def candidate(xs), do: derivative(xs)\n  def derivative(xs) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_62_derivative.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'derivative' do\n    assert [1, 4, 12, 20] == HumanEval.candidate([3, 1, 2, 4, 5])\n    assert [2, 6] == HumanEval.candidate([1, 2, 3])\n    assert [2, 2] == HumanEval.candidate([3, 2, 1])\n    assert [2, 2, 0, 16] == HumanEval.candidate([3, 2, 1, 0, 4])\n    assert [] == HumanEval.candidate([1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_63_fibfib", "language": "elixir", "prompt": "# The FibFib number sequence is a sequence similar to the Fibbonacci sequnece that's defined as follows:\n# fibfib(0) == 0\n# fibfib(1) == 0\n# fibfib(2) == 1\n# fibfib(n) == fibfib(n-1) + fibfib(n-2) + fibfib(n-3).\n# Please write a function to efficiently compute the n-th element of the fibfib number sequence.\n# >>> HumanEval.fibfib(1)\n# 0\n# >>> HumanEval.fibfib(5)\n# 4\n# >>> HumanEval.fibfib(8)\n# 24\n\ndefmodule HumanEval do\n  def candidate(n), do: fibfib(n)\n  def fibfib(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_63_fibfib.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fibfib' do\n    assert 1 == HumanEval.candidate(2)\n    assert 0 == HumanEval.candidate(1)\n    assert 4 == HumanEval.candidate(5)\n    assert 24 == HumanEval.candidate(8)\n    assert 81 == HumanEval.candidate(10)\n    assert 274 == HumanEval.candidate(12)\n    assert 927 == HumanEval.candidate(14)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_64_vowels_count", "language": "elixir", "prompt": "# Write a function vowels_count which takes a string representing\n# a word as input and returns the number of vowels in the string.\n# Vowels in this case are 'a', 'e', 'i', 'o', 'u'. Here, 'y' is also a\n# vowel, but only when it is at the end of the given word.\n# Example:\n# >>> HumanEval.vowels_count(\"abcde\")\n# 2\n# >>> HumanEval.vowels_count(\"ACEDY\")\n# 3\n\ndefmodule HumanEval do\n  def candidate(s), do: vowels_count(s)\n  def vowels_count(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_64_vowels_count.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'vowels_count' do\n    assert 2 == HumanEval.candidate(\"abcde\")\n    assert 3 == HumanEval.candidate(\"Alone\")\n    assert 2 == HumanEval.candidate(\"key\")\n    assert 1 == HumanEval.candidate(\"bye\")\n    assert 2 == HumanEval.candidate(\"keY\")\n    assert 1 == HumanEval.candidate(\"bYe\")\n    assert 3 == HumanEval.candidate(\"ACEDY\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_65_circular_shift", "language": "elixir", "prompt": "# Circular shift the digits of the integer x, shift the digits right by shift\n# and return the result as a string.\n# If shift > number of digits, return digits reversed.\n# >>> HumanEval.circular_shift(12, 1)\n# \"21\"\n# >>> HumanEval.circular_shift(12, 2)\n# \"12\"\n\ndefmodule HumanEval do\n  def candidate(x, shift), do: circular_shift(x, shift)\n  def circular_shift(x, shift) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_65_circular_shift.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'circular_shift' do\n    assert \"001\" == HumanEval.candidate(100, 2)\n    assert \"12\" == HumanEval.candidate(12, 2)\n    assert \"79\" == HumanEval.candidate(97, 8)\n    assert \"21\" == HumanEval.candidate(12, 1)\n    assert \"11\" == HumanEval.candidate(11, 101)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_66_digitSum", "language": "elixir", "prompt": "# Task\n# Write a function that takes a string as input and returns the sum of the upper characters only'\n# ASCII codes.\n# Examples:\n# >>> HumanEval.digitSum(\"\")\n# 0\n# >>> HumanEval.digitSum(\"abAB\")\n# 131\n# >>> HumanEval.digitSum(\"abcCd\")\n# 67\n# >>> HumanEval.digitSum(\"helloE\")\n# 69\n# >>> HumanEval.digitSum(\"woArBld\")\n# 131\n# >>> HumanEval.digitSum(\"aAaaaXa\")\n# 153\n\ndefmodule HumanEval do\n  def candidate(s), do: digitSum(s)\n  def digitSum(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_66_digitSum.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'digitSum' do\n    assert 0 == HumanEval.candidate(\"\")\n    assert 131 == HumanEval.candidate(\"abAB\")\n    assert 67 == HumanEval.candidate(\"abcCd\")\n    assert 69 == HumanEval.candidate(\"helloE\")\n    assert 131 == HumanEval.candidate(\"woArBld\")\n    assert 153 == HumanEval.candidate(\"aAaaaXa\")\n    assert 151 == HumanEval.candidate(\" How are yOu?\")\n    assert 327 == HumanEval.candidate(\"You arE Very Smart\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_67_fruit_distribution", "language": "elixir", "prompt": "# In this task, you will be given a string that represents a number of apples and oranges \n# that are distributed in a basket of fruit this basket contains \n# apples, oranges, and mango fruits. Given the string that represents the total number of \n# the oranges and apples and an integer that represent the total number of the fruits \n# in the basket return the number of the mango fruits in the basket.\n# for examble:\n# >>> HumanEval.fruit_distribution(\"5 apples and 6 oranges\", 19)\n# 8\n# >>> HumanEval.fruit_distribution(\"0 apples and 1 oranges\", 3)\n# 2\n# >>> HumanEval.fruit_distribution(\"2 apples and 3 oranges\", 100)\n# 95\n# >>> HumanEval.fruit_distribution(\"100 apples and 1 oranges\", 120)\n# 19\n\ndefmodule HumanEval do\n  def candidate(s, n), do: fruit_distribution(s, n)\n  def fruit_distribution(s, n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_67_fruit_distribution.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'fruit_distribution' do\n    assert 8 == HumanEval.candidate(\"5 apples and 6 oranges\", 19)\n    assert 10 == HumanEval.candidate(\"5 apples and 6 oranges\", 21)\n    assert 2 == HumanEval.candidate(\"0 apples and 1 oranges\", 3)\n    assert 2 == HumanEval.candidate(\"1 apples and 0 oranges\", 3)\n    assert 95 == HumanEval.candidate(\"2 apples and 3 oranges\", 100)\n    assert 0 == HumanEval.candidate(\"2 apples and 3 oranges\", 5)\n    assert 19 == HumanEval.candidate(\"1 apples and 100 oranges\", 120)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_68_pluck", "language": "elixir", "prompt": "# \"Given an array representing a branch of a tree that has non-negative integer nodes\n# your task is to pluck one of the nodes and return it.\n# The plucked node should be the node with the smallest even value.\n# If multiple nodes with the same smallest even value are found return the node that has smallest index.\n# The plucked node should be returned in a list, [ smalest_value, its index ],\n# If there are no even values or the given array is empty, return [].\n# Example 1:\n# >>> HumanEval.pluck([4, 2, 3])\n# [2, 1]\n# Explanation: 2 has the smallest even value, and 2 has the smallest index.\n# Example 2:\n# >>> HumanEval.pluck([1, 2, 3])\n# [2, 1]\n# Explanation: 2 has the smallest even value, and 2 has the smallest index.\n# Example 3:\n# >>> HumanEval.pluck([])\n# []\n# Example 4:\n# >>> HumanEval.pluck([5, 0, 3, 0, 4, 2])\n# [0, 1]\n# Explanation: 0 is the smallest value, but  there are two zeros,\n# so we will choose the first zero, which has the smallest index.\n# Constraints:\n# * 1 <= nodes.length <= 10000\n# * 0 <= node.value\n\ndefmodule HumanEval do\n  def candidate(arr), do: pluck(arr)\n  def pluck(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_68_pluck.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'pluck' do\n    assert [2, 1] == HumanEval.candidate([4, 2, 3])\n    assert [2, 1] == HumanEval.candidate([1, 2, 3])\n    assert [] == HumanEval.candidate([])\n    assert [0, 1] == HumanEval.candidate([5, 0, 3, 0, 4, 2])\n    assert [0, 3] == HumanEval.candidate([1, 2, 3, 0, 5, 3])\n    assert [4, 1] == HumanEval.candidate([5, 4, 8, 4, 8])\n    assert [6, 1] == HumanEval.candidate([7, 6, 7, 1])\n    assert [] == HumanEval.candidate([7, 9, 7, 1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_69_search", "language": "elixir", "prompt": "# You are given a non-empty list of positive integers. Return the greatest integer that is greater than \n# zero, and has a frequency greater than or equal to the value of the integer itself. \n# The frequency of an integer is the number of times it appears in the list.\n# If no such a value exist, return -1.\n# Examples:\n# >>> HumanEval.search([4, 1, 2, 2, 3, 1])\n# 2\n# >>> HumanEval.search([1, 2, 2, 3, 3, 3, 4, 4, 4])\n# 3\n# >>> HumanEval.search([5, 5, 4, 4, 4])\n# -1\n\ndefmodule HumanEval do\n  def candidate(lst), do: search(lst)\n  def search(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_69_search.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'search' do\n    assert 1 == HumanEval.candidate([5, 5, 5, 5, 1])\n    assert 4 == HumanEval.candidate([4, 1, 4, 1, 4, 4])\n    assert -1 == HumanEval.candidate([3, 3])\n    assert 8 == HumanEval.candidate([8, 8, 8, 8, 8, 8, 8, 8])\n    assert 2 == HumanEval.candidate([2, 3, 3, 2, 2])\n    assert 1 == HumanEval.candidate([2, 7, 8, 8, 4, 8, 7, 3, 9, 6, 5, 10, 4, 3, 6, 7, 1, 7, 4, 10, 8, 1])\n    assert 2 == HumanEval.candidate([3, 2, 8, 2])\n    assert 1 == HumanEval.candidate([6, 7, 1, 8, 8, 10, 5, 8, 5, 3, 10])\n    assert -1 == HumanEval.candidate([8, 8, 3, 6, 5, 6, 4])\n    assert 1 == HumanEval.candidate([6, 9, 6, 7, 1, 4, 7, 1, 8, 8, 9, 8, 10, 10, 8, 4, 10, 4, 10, 1, 2, 9, 5, 7, 9])\n    assert 1 == HumanEval.candidate([1, 9, 10, 1, 3])\n    assert 5 == HumanEval.candidate([6, 9, 7, 5, 8, 7, 5, 3, 7, 5, 10, 10, 3, 6, 10, 2, 8, 6, 5, 4, 9, 5, 3, 10])\n    assert 1 == HumanEval.candidate([1])\n    assert 4 == HumanEval.candidate([8, 8, 10, 6, 4, 3, 5, 8, 2, 4, 2, 8, 4, 6, 10, 4, 2, 1, 10, 2, 1, 1, 5])\n    assert 2 == HumanEval.candidate([2, 10, 4, 8, 2, 10, 5, 1, 2, 9, 5, 5, 6, 3, 8, 6, 4, 10])\n    assert 1 == HumanEval.candidate([1, 6, 10, 1, 6, 9, 10, 8, 6, 8, 7, 3])\n    assert 4 == HumanEval.candidate([9, 2, 4, 1, 5, 1, 5, 2, 5, 7, 7, 7, 3, 10, 1, 5, 4, 2, 8, 4, 1, 9, 10, 7, 10, 2, 8, 10, 9, 4])\n    assert 4 == HumanEval.candidate([2, 6, 4, 2, 8, 7, 5, 6, 4, 10, 4, 6, 3, 7, 8, 8, 3, 1, 4, 2, 2, 10, 7])\n    assert 2 == HumanEval.candidate([9, 8, 6, 10, 2, 6, 10, 2, 7, 8, 10, 3, 8, 2, 6, 2, 3, 1])\n    assert -1 == HumanEval.candidate([5, 5, 3, 9, 5, 6, 3, 2, 8, 5, 6, 10, 10, 6, 8, 4, 10, 7, 7, 10, 8])\n    assert -1 == HumanEval.candidate([10])\n    assert 2 == HumanEval.candidate([9, 7, 7, 2, 4, 7, 2, 10, 9, 7, 5, 7, 2])\n    assert 1 == HumanEval.candidate([5, 4, 10, 2, 1, 1, 10, 3, 6, 1, 8])\n    assert 1 == HumanEval.candidate([7, 9, 9, 9, 3, 4, 1, 5, 9, 1, 2, 1, 1, 10, 7, 5, 6, 7, 6, 7, 7, 6])\n    assert -1 == HumanEval.candidate([3, 10, 10, 9, 2])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_6_parse_nested_parens", "language": "elixir", "prompt": "# Input to this function is a string represented multiple groups for nested parentheses separated by spaces.\n# For each of the group, output the deepest level of nesting of parentheses.\n# E.g. (()()) has maximum two levels of nesting while ((())) has three.\n# >>> HumanEval.parse_nested_parens(\"(()()) ((())) () ((())()())\")\n# [2, 3, 1, 3]\n\ndefmodule HumanEval do\n  def candidate(paren_string), do: parse_nested_parens(paren_string)\n  def parse_nested_parens(paren_string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_6_parse_nested_parens.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'parse_nested_parens' do\n    assert [2, 3, 1, 3] == HumanEval.candidate(\"(()()) ((())) () ((())()())\")\n    assert [1, 2, 3, 4] == HumanEval.candidate(\"() (()) ((())) (((())))\")\n    assert [4] == HumanEval.candidate(\"(()(())((())))\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_70_strange_sort_list", "language": "elixir", "prompt": "# Given list of integers, return list in strange order.\n# Strange sorting, is when you start with the minimum value,\n# then maximum of the remaining integers, then minimum and so on.\n# Examples:\n# >>> HumanEval.strange_sort_list([1, 2, 3, 4])\n# [1, 4, 2, 3]\n# >>> HumanEval.strange_sort_list([5, 5, 5, 5])\n# [5, 5, 5, 5]\n# >>> HumanEval.strange_sort_list([])\n# []\n\ndefmodule HumanEval do\n  def candidate(lst), do: strange_sort_list(lst)\n  def strange_sort_list(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_70_strange_sort_list.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'strange_sort_list' do\n    assert [1, 4, 2, 3] == HumanEval.candidate([1, 2, 3, 4])\n    assert [5, 9, 6, 8, 7] == HumanEval.candidate([5, 6, 7, 8, 9])\n    assert [1, 5, 2, 4, 3] == HumanEval.candidate([1, 2, 3, 4, 5])\n    assert [1, 9, 5, 8, 6, 7] == HumanEval.candidate([5, 6, 7, 8, 9, 1])\n    assert [5, 5, 5, 5] == HumanEval.candidate([5, 5, 5, 5])\n    assert [] == HumanEval.candidate([])\n    assert [1, 8, 2, 7, 3, 6, 4, 5] == HumanEval.candidate([1, 2, 3, 4, 5, 6, 7, 8])\n    assert [-5, 5, -5, 5, 0, 2, 2, 2] == HumanEval.candidate([0, 2, 2, 2, 5, 5, -5, -5])\n    assert [111111] == HumanEval.candidate([111111])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_71_triangle_area", "language": "elixir", "prompt": "# Given the lengths of the three sides of a triangle. Return the area of\n# the triangle rounded to 2 decimal points if the three sides form a valid triangle. \n# Otherwise return -1\n# Three sides make a valid triangle when the sum of any two sides is greater \n# than the third side.\n# Example:\n# >>> HumanEval.triangle_area(3, 4, 5)\n# 6.0\n# >>> HumanEval.triangle_area(1, 2, 10)\n# -1\n\ndefmodule HumanEval do\n  def candidate(a, b, c), do: triangle_area(a, b, c)\n  def triangle_area(a, b, c) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_71_triangle_area.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'triangle_area' do\n    assert 6.0 == HumanEval.candidate(3, 4, 5)\n    assert -1 == HumanEval.candidate(1, 2, 10)\n    assert 8.18 == HumanEval.candidate(4, 8, 5)\n    assert 1.73 == HumanEval.candidate(2, 2, 2)\n    assert -1 == HumanEval.candidate(1, 2, 3)\n    assert 16.25 == HumanEval.candidate(10, 5, 7)\n    assert -1 == HumanEval.candidate(2, 6, 3)\n    assert 0.43 == HumanEval.candidate(1, 1, 1)\n    assert -1 == HumanEval.candidate(2, 2, 10)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_72_will_it_fly", "language": "elixir", "prompt": "# Write a function that returns True if the object q will fly, and False otherwise.\n# The object q will fly if it's balanced (it is a palindromic list) and the sum of its elements is less than or equal the maximum possible weight w.\n# Example:\n# >>> HumanEval.will_it_fly([1, 2], 5)\n# false\n# # 1+2 is less than the maximum possible weight, but it's unbalanced.\n# >>> HumanEval.will_it_fly([3, 2, 3], 1)\n# false\n# # it's balanced, but 3+2+3 is more than the maximum possible weight.\n# >>> HumanEval.will_it_fly([3, 2, 3], 9)\n# true\n# # 3+2+3 is less than the maximum possible weight, and it's balanced.\n# >>> HumanEval.will_it_fly([3], 5)\n# true\n# # 3 is less than the maximum possible weight, and it's balanced.\n\ndefmodule HumanEval do\n  def candidate(q, w), do: will_it_fly(q, w)\n  def will_it_fly(q, w) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_72_will_it_fly.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'will_it_fly' do\n    assert true == HumanEval.candidate([3, 2, 3], 9)\n    assert false == HumanEval.candidate([1, 2], 5)\n    assert true == HumanEval.candidate([3], 5)\n    assert false == HumanEval.candidate([3, 2, 3], 1)\n    assert false == HumanEval.candidate([1, 2, 3], 6)\n    assert true == HumanEval.candidate([5], 5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_73_smallest_change", "language": "elixir", "prompt": "# Given an array arr of integers, find the minimum number of elements that\n# need to be changed to make the array palindromic. A palindromic array is an array that\n# is read the same backwards and forwards. In one change, you can change one element to any other element.\n# For example:\n# >>> HumanEval.smallest_change([1, 2, 3, 5, 4, 7, 9, 6])\n# 4\n# >>> HumanEval.smallest_change([1, 2, 3, 4, 3, 2, 2])\n# 1\n# >>> HumanEval.smallest_change([1, 2, 3, 2, 1])\n# 0\n\ndefmodule HumanEval do\n  def candidate(arr), do: smallest_change(arr)\n  def smallest_change(arr) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_73_smallest_change.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'smallest_change' do\n    assert 4 == HumanEval.candidate([1, 2, 3, 5, 4, 7, 9, 6])\n    assert 1 == HumanEval.candidate([1, 2, 3, 4, 3, 2, 2])\n    assert 1 == HumanEval.candidate([1, 4, 2])\n    assert 1 == HumanEval.candidate([1, 4, 4, 2])\n    assert 0 == HumanEval.candidate([1, 2, 3, 2, 1])\n    assert 0 == HumanEval.candidate([3, 1, 1, 3])\n    assert 0 == HumanEval.candidate([1])\n    assert 1 == HumanEval.candidate([0, 1])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_74_total_match", "language": "elixir", "prompt": "# Write a function that accepts two lists of strings and returns the list that has \n# total number of chars in the all strings of the list less than the other list.\n# if the two lists have the same number of chars, return the first list.\n# Examples\n# >>> HumanEval.total_match([], [])\n# []\n# >>> HumanEval.total_match([\"hi\", \"admin\"], [\"hI\", \"Hi\"])\n# [\"hI\", \"Hi\"]\n# >>> HumanEval.total_match([\"hi\", \"admin\"], [\"hi\", \"hi\", \"admin\", \"project\"])\n# [\"hi\", \"admin\"]\n# >>> HumanEval.total_match([\"hi\", \"admin\"], [\"hI\", \"hi\", \"hi\"])\n# [\"hI\", \"hi\", \"hi\"]\n# >>> HumanEval.total_match([\"4\"], [\"1\", \"2\", \"3\", \"4\", \"5\"])\n# [\"4\"]\n\ndefmodule HumanEval do\n  def candidate(lst1, lst2), do: total_match(lst1, lst2)\n  def total_match(lst1, lst2) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_74_total_match.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'total_match' do\n    assert [] == HumanEval.candidate([], [])\n    assert [\"hi\", \"hi\"] == HumanEval.candidate([\"hi\", \"admin\"], [\"hi\", \"hi\"])\n    assert [\"hi\", \"admin\"] == HumanEval.candidate([\"hi\", \"admin\"], [\"hi\", \"hi\", \"admin\", \"project\"])\n    assert [\"4\"] == HumanEval.candidate([\"4\"], [\"1\", \"2\", \"3\", \"4\", \"5\"])\n    assert [\"hI\", \"Hi\"] == HumanEval.candidate([\"hi\", \"admin\"], [\"hI\", \"Hi\"])\n    assert [\"hI\", \"hi\", \"hi\"] == HumanEval.candidate([\"hi\", \"admin\"], [\"hI\", \"hi\", \"hi\"])\n    assert [\"hi\", \"admin\"] == HumanEval.candidate([\"hi\", \"admin\"], [\"hI\", \"hi\", \"hii\"])\n    assert [] == HumanEval.candidate([], [\"this\"])\n    assert [] == HumanEval.candidate([\"this\"], [])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_75_is_multiply_prime", "language": "elixir", "prompt": "# Write a function that returns true if the given number is the multiplication of 3 prime numbers\n# and false otherwise.\n# Knowing that (a) is less then 100. \n# Example:\n# >>> HumanEval.is_multiply_prime(30)\n# true\n# 30 = 2 * 3 * 5\n\ndefmodule HumanEval do\n  def candidate(a), do: is_multiply_prime(a)\n  def is_multiply_prime(a) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_75_is_multiply_prime.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_multiply_prime' do\n    assert false == HumanEval.candidate(5)\n    assert true == HumanEval.candidate(30)\n    assert true == HumanEval.candidate(8)\n    assert false == HumanEval.candidate(10)\n    assert true == HumanEval.candidate(125)\n    assert true == HumanEval.candidate(105)\n    assert false == HumanEval.candidate(126)\n    assert false == HumanEval.candidate(729)\n    assert false == HumanEval.candidate(891)\n    assert true == HumanEval.candidate(1001)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_76_is_simple_power", "language": "elixir", "prompt": "# Your task is to write a function that returns true if a number x is a simple\n# power of n and false in other cases.\n# x is a simple power of n if n**int=x\n# For example:\n# >>> HumanEval.is_simple_power(1, 4)\n# true\n# >>> HumanEval.is_simple_power(2, 2)\n# true\n# >>> HumanEval.is_simple_power(8, 2)\n# true\n# >>> HumanEval.is_simple_power(3, 2)\n# false\n# >>> HumanEval.is_simple_power(3, 1)\n# false\n# >>> HumanEval.is_simple_power(5, 3)\n# false\n\ndefmodule HumanEval do\n  def candidate(x, n), do: is_simple_power(x, n)\n  def is_simple_power(x, n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_76_is_simple_power.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_simple_power' do\n    assert true == HumanEval.candidate(16, 2)\n    assert false == HumanEval.candidate(143214, 16)\n    assert true == HumanEval.candidate(4, 2)\n    assert true == HumanEval.candidate(9, 3)\n    assert true == HumanEval.candidate(16, 4)\n    assert false == HumanEval.candidate(24, 2)\n    assert false == HumanEval.candidate(128, 4)\n    assert false == HumanEval.candidate(12, 6)\n    assert true == HumanEval.candidate(1, 1)\n    assert true == HumanEval.candidate(1, 12)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_77_iscube", "language": "elixir", "prompt": "# Write a function that takes an integer a and returns True \n# if this ingeger is a cube of some integer number.\n# Note: you may assume the input is always valid.\n# Examples:\n# >>> HumanEval.iscube(1)\n# true\n# >>> HumanEval.iscube(2)\n# false\n# >>> HumanEval.iscube(-1)\n# true\n# >>> HumanEval.iscube(64)\n# true\n# >>> HumanEval.iscube(0)\n# true\n# >>> HumanEval.iscube(180)\n# false\n\ndefmodule HumanEval do\n  def candidate(a), do: iscube(a)\n  def iscube(a) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_77_iscube.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'iscube' do\n    assert true == HumanEval.candidate(1)\n    assert false == HumanEval.candidate(2)\n    assert true == HumanEval.candidate(-1)\n    assert true == HumanEval.candidate(64)\n    assert false == HumanEval.candidate(180)\n    assert true == HumanEval.candidate(1000)\n    assert true == HumanEval.candidate(0)\n    assert false == HumanEval.candidate(1729)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_78_hex_key", "language": "elixir", "prompt": "# You have been tasked to write a function that receives \n# a hexadecimal number as a string and counts the number of hexadecimal \n# digits that are primes (prime number, or a prime, is a natural number \n# greater than 1 that is not a product of two smaller natural numbers).\n# Hexadecimal digits are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F.\n# Prime numbers are 2, 3, 5, 7, 11, 13, 17,...\n# So you have to determine a number of the following digits: 2, 3, 5, 7, \n# B (=decimal 11), D (=decimal 13).\n# Note: you may assume the input is always correct or empty string, \n# and symbols A,B,C,D,E,F are always uppercase.\n# Examples:\n# >>> HumanEval.hex_key(\"AB\")\n# 1\n# >>> HumanEval.hex_key(\"1077E\")\n# 2\n# >>> HumanEval.hex_key(\"ABED1A33\")\n# 4\n# >>> HumanEval.hex_key(\"123456789ABCDEF0\")\n# 6\n# >>> HumanEval.hex_key(\"2020\")\n# 2\n\ndefmodule HumanEval do\n  def candidate(num), do: hex_key(num)\n  def hex_key(num) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_78_hex_key.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'hex_key' do\n    assert 1 == HumanEval.candidate(\"AB\")\n    assert 2 == HumanEval.candidate(\"1077E\")\n    assert 4 == HumanEval.candidate(\"ABED1A33\")\n    assert 2 == HumanEval.candidate(\"2020\")\n    assert 6 == HumanEval.candidate(\"123456789ABCDEF0\")\n    assert 12 == HumanEval.candidate(\"112233445566778899AABBCCDDEEFF00\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_79_decimal_to_binary", "language": "elixir", "prompt": "# You will be given a number in decimal form and your task is to convert it to\n# binary format. The function should return a string, with each character representing a binary\n# number. Each character in the string will be '0' or '1'.\n# There will be an extra couple of characters 'db' at the beginning and at the end of the string.\n# The extra characters are there to help with the format.\n# Examples:\n# >>> HumanEval.decimal_to_binary(15)\n# \"db1111db\"\n# >>> HumanEval.decimal_to_binary(32)\n# \"db100000db\"\n\ndefmodule HumanEval do\n  def candidate(decimal), do: decimal_to_binary(decimal)\n  def decimal_to_binary(decimal) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_79_decimal_to_binary.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'decimal_to_binary' do\n    assert \"db0db\" == HumanEval.candidate(0)\n    assert \"db100000db\" == HumanEval.candidate(32)\n    assert \"db1100111db\" == HumanEval.candidate(103)\n    assert \"db1111db\" == HumanEval.candidate(15)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_7_filter_by_substring", "language": "elixir", "prompt": "# Filter an input list of strings only for ones that contain given substring\n# >>> HumanEval.filter_by_substring([], \"a\")\n# []\n# >>> HumanEval.filter_by_substring([\"abc\", \"bacd\", \"cde\", \"array\"], \"a\")\n# [\"abc\", \"bacd\", \"array\"]\n\ndefmodule HumanEval do\n  def candidate(strings, substring), do: filter_by_substring(strings, substring)\n  def filter_by_substring(strings, substring) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_7_filter_by_substring.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'filter_by_substring' do\n    assert [] == HumanEval.candidate([], \"john\")\n    assert [\"xxx\", \"xxxAAA\", \"xxx\"] == HumanEval.candidate([\"xxx\", \"asd\", \"xxy\", \"john doe\", \"xxxAAA\", \"xxx\"], \"xxx\")\n    assert [\"xxx\", \"aaaxxy\", \"xxxAAA\", \"xxx\"] == HumanEval.candidate([\"xxx\", \"asd\", \"aaaxxy\", \"john doe\", \"xxxAAA\", \"xxx\"], \"xx\")\n    assert [\"grunt\", \"prune\"] == HumanEval.candidate([\"grunt\", \"trumpet\", \"prune\", \"gruesome\"], \"run\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_80_is_happy", "language": "elixir", "prompt": "# You are given a string s.\n# Your task is to check if the string is happy or not.\n# A string is happy if its length is at least 3 and every 3 consecutive letters are distinct\n# For example:\n# >>> HumanEval.is_happy(\"a\")\n# false\n# >>> HumanEval.is_happy(\"aa\")\n# false\n# >>> HumanEval.is_happy(\"abcd\")\n# true\n# >>> HumanEval.is_happy(\"aabb\")\n# false\n# >>> HumanEval.is_happy(\"adb\")\n# true\n# >>> HumanEval.is_happy(\"xyy\")\n# false\n\ndefmodule HumanEval do\n  def candidate(s), do: is_happy(s)\n  def is_happy(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_80_is_happy.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_happy' do\n    assert false == HumanEval.candidate(\"a\")\n    assert false == HumanEval.candidate(\"aa\")\n    assert true == HumanEval.candidate(\"abcd\")\n    assert false == HumanEval.candidate(\"aabb\")\n    assert true == HumanEval.candidate(\"adb\")\n    assert false == HumanEval.candidate(\"xyy\")\n    assert true == HumanEval.candidate(\"iopaxpoi\")\n    assert false == HumanEval.candidate(\"iopaxioi\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_81_numerical_letter_grade", "language": "elixir", "prompt": "# It is the last week of the semester and the teacher has to give the grades\n# to students. The teacher has been making her own algorithm for grading.\n# The only problem is, she has lost the code she used for grading.\n# She has given you a list of GPAs for some students and you have to write \n# a function that can output a list of letter grades using the following table:\n# GPA       |    Letter grade\n# 4.0                A+\n# > 3.7                A \n# > 3.3                A- \n# > 3.0                B+\n# > 2.7                B \n# > 2.3                B-\n# > 2.0                C+\n# > 1.7                C\n# > 1.3                C-\n# > 1.0                D+ \n# > 0.7                D \n# > 0.0                D-\n# 0.0                E\n# Example:\n# >>> HumanEval.grade_equation([4.0, 3, 1.7, 2, 3.5])\n# [\"A+\", \"B\", \"C-\", \"C\", \"A-\"]\n\ndefmodule HumanEval do\n  def candidate(grades), do: numerical_letter_grade(grades)\n  def numerical_letter_grade(grades) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_81_numerical_letter_grade.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'numerical_letter_grade' do\n    assert [\"A+\", \"B\", \"C-\", \"C\", \"A-\"] == HumanEval.candidate([4.0, 3, 1.7, 2, 3.5])\n    assert [\"D+\"] == HumanEval.candidate([1.2])\n    assert [\"D-\"] == HumanEval.candidate([0.5])\n    assert [\"E\"] == HumanEval.candidate([0.0])\n    assert [\"D\", \"D-\", \"C-\", \"B\", \"B+\"] == HumanEval.candidate([1.0, 0.3, 1.5, 2.8, 3.3])\n    assert [\"E\", \"D-\"] == HumanEval.candidate([0.0, 0.7])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_82_prime_length", "language": "elixir", "prompt": "# Write a function that takes a string and returns True if the string\n# length is a prime number or False otherwise\n# Examples\n# >>> HumanEval.prime_length(\"Hello\")\n# true\n# >>> HumanEval.prime_length(\"abcdcba\")\n# true\n# >>> HumanEval.prime_length(\"kittens\")\n# true\n# >>> HumanEval.prime_length(\"orange\")\n# false\n\ndefmodule HumanEval do\n  def candidate(string), do: prime_length(string)\n  def prime_length(string) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_82_prime_length.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'prime_length' do\n    assert true == HumanEval.candidate(\"Hello\")\n    assert true == HumanEval.candidate(\"abcdcba\")\n    assert true == HumanEval.candidate(\"kittens\")\n    assert false == HumanEval.candidate(\"orange\")\n    assert true == HumanEval.candidate(\"wow\")\n    assert true == HumanEval.candidate(\"world\")\n    assert true == HumanEval.candidate(\"MadaM\")\n    assert true == HumanEval.candidate(\"Wow\")\n    assert false == HumanEval.candidate(\"\")\n    assert true == HumanEval.candidate(\"HI\")\n    assert true == HumanEval.candidate(\"go\")\n    assert false == HumanEval.candidate(\"gogo\")\n    assert false == HumanEval.candidate(\"aaaaaaaaaaaaaaa\")\n    assert true == HumanEval.candidate(\"Madam\")\n    assert false == HumanEval.candidate(\"M\")\n    assert false == HumanEval.candidate(\"0\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_83_starts_one_ends", "language": "elixir", "prompt": "# Given a positive integer n, return the count of the numbers of n-digit\n# positive integers that start or end with 1.\n\ndefmodule HumanEval do\n  def candidate(n), do: starts_one_ends(n)\n  def starts_one_ends(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_83_starts_one_ends.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'starts_one_ends' do\n    assert 1 == HumanEval.candidate(1)\n    assert 18 == HumanEval.candidate(2)\n    assert 180 == HumanEval.candidate(3)\n    assert 1800 == HumanEval.candidate(4)\n    assert 18000 == HumanEval.candidate(5)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_84_solve", "language": "elixir", "prompt": "# Given a positive integer N, return the total sum of its digits in binary.\n# Example\n# >>> HumanEval.solve(1000)\n# \"1\"\n# >>> HumanEval.solve(150)\n# \"110\"\n# >>> HumanEval.solve(147)\n# \"1100\"\n# Variables:\n# @N integer\n# Constraints: 0 \u2264 N \u2264 10000.\n# Output:\n# a string of binary number\n\ndefmodule HumanEval do\n  def candidate(N), do: solve(N)\n  def solve(N) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_84_solve.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'solve' do\n    assert \"1\" == HumanEval.candidate(1000)\n    assert \"110\" == HumanEval.candidate(150)\n    assert \"1100\" == HumanEval.candidate(147)\n    assert \"1001\" == HumanEval.candidate(333)\n    assert \"10010\" == HumanEval.candidate(963)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_85_add", "language": "elixir", "prompt": "# Given a non-empty list of integers lst. add the even elements that are at odd indices..\n# Examples:\n# >>> HumanEval.add([4, 2, 6, 7])\n# 2\n\ndefmodule HumanEval do\n  def candidate(lst), do: add(lst)\n  def add(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_85_add.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'add' do\n    assert 88 == HumanEval.candidate([4, 88])\n    assert 122 == HumanEval.candidate([4, 5, 6, 7, 2, 122])\n    assert 0 == HumanEval.candidate([4, 0, 6, 7])\n    assert 12 == HumanEval.candidate([4, 4, 6, 8])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_86_anti_shuffle", "language": "elixir", "prompt": "# Write a function that takes a string and returns an ordered version of it.\n# Ordered version of string, is a string where all words (separated by space)\n# are replaced by a new word where all the characters arranged in\n# ascending order based on ascii value.\n# Note: You should keep the order of words and blank spaces in the sentence.\n# For example:\n# >>> HumanEval.anti_shuffle(\"Hi\")\n# \"Hi\"\n# >>> HumanEval.anti_shuffle(\"hello\")\n# \"ehllo\"\n# >>> HumanEval.anti_shuffle(\"Hello World!!!\")\n# \"Hello !!!Wdlor\"\n\ndefmodule HumanEval do\n  def candidate(s), do: anti_shuffle(s)\n  def anti_shuffle(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_86_anti_shuffle.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'anti_shuffle' do\n    assert \"Hi\" == HumanEval.candidate(\"Hi\")\n    assert \"ehllo\" == HumanEval.candidate(\"hello\")\n    assert \"bemnru\" == HumanEval.candidate(\"number\")\n    assert \"abcd\" == HumanEval.candidate(\"abcd\")\n    assert \"Hello !!!Wdlor\" == HumanEval.candidate(\"Hello World!!!\")\n    assert \"\" == HumanEval.candidate(\"\")\n    assert \".Hi My aemn is Meirst .Rboot How aer ?ouy\" == HumanEval.candidate(\"Hi. My name is Mister Robot. How are you?\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_87_get_row", "language": "elixir", "prompt": "# You are given a 2 dimensional data, as a nested lists,\n# which is similar to matrix, however, unlike matrices,\n# each row may contain a different number of columns.\n# Given lst, and integer x, find integers x in the list,\n# and return list of tuples, [(x1, y1), (x2, y2) ...] such that\n# each tuple is a coordinate - (row, columns), starting with 0.\n# Sort coordinates initially by rows in ascending order.\n# Also, sort coordinates of the row by columns in descending order.\n# Examples:\n# >>> HumanEval.get_row([[1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 1, 6], [1, 2, 3, 4, 5, 1]], 1)\n# [{0, 0}, {1, 4}, {1, 0}, {2, 5}, {2, 0}]\n# >>> HumanEval.get_row([], 1)\n# []\n# >>> HumanEval.get_row([[], [1], [1, 2, 3]], 3)\n# [{2, 2}]\n\ndefmodule HumanEval do\n  def candidate(lst, x), do: get_row(lst, x)\n  def get_row(lst, x) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_87_get_row.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'get_row' do\n    assert [{0, 0}, {1, 4}, {1, 0}, {2, 5}, {2, 0}] == HumanEval.candidate([[1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 1, 6], [1, 2, 3, 4, 5, 1]], 1)\n    assert [{0, 1}, {1, 1}, {2, 1}, {3, 1}, {4, 1}, {5, 1}] == HumanEval.candidate([[1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6]], 2)\n    assert [{0, 0}, {1, 0}, {2, 1}, {2, 0}, {3, 2}, {3, 0}, {4, 3}, {4, 0}, {5, 4}, {5, 0}, {6, 5}, {6, 0}] == HumanEval.candidate([[1, 2, 3, 4, 5, 6], [1, 2, 3, 4, 5, 6], [1, 1, 3, 4, 5, 6], [1, 2, 1, 4, 5, 6], [1, 2, 3, 1, 5, 6], [1, 2, 3, 4, 1, 6], [1, 2, 3, 4, 5, 1]], 1)\n    assert [] == HumanEval.candidate([], 1)\n    assert [] == HumanEval.candidate([[1]], 2)\n    assert [{2, 2}] == HumanEval.candidate([[], [1], [1, 2, 3]], 3)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_88_sort_array", "language": "elixir", "prompt": "# Given an array of non-negative integers, return a copy of the given array after sorting,\n# you will sort the given array in ascending order if the sum( first index value, last index value) is odd,\n# or sort it in descending order if the sum( first index value, last index value) is even.\n# Note:\n# * don't change the given array.\n# Examples:\n# >>> HumanEval.sort_array([])\n# []\n# >>> HumanEval.sort_array([5])\n# [5]\n# >>> HumanEval.sort_array([2, 4, 3, 0, 1, 5])\n# [0, 1, 2, 3, 4, 5]\n# >>> HumanEval.sort_array([2, 4, 3, 0, 1, 5, 6])\n# [6, 5, 4, 3, 2, 1, 0]\n\ndefmodule HumanEval do\n  def candidate(array), do: sort_array(array)\n  def sort_array(array) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_88_sort_array.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sort_array' do\n    assert [] == HumanEval.candidate([])\n    assert [5] == HumanEval.candidate([5])\n    assert [0, 1, 2, 3, 4, 5] == HumanEval.candidate([2, 4, 3, 0, 1, 5])\n    assert [6, 5, 4, 3, 2, 1, 0] == HumanEval.candidate([2, 4, 3, 0, 1, 5, 6])\n    assert [1, 2] == HumanEval.candidate([2, 1])\n    assert [0, 11, 15, 32, 42, 87] == HumanEval.candidate([15, 42, 87, 32, 11, 0])\n    assert [23, 21, 14, 11] == HumanEval.candidate([21, 14, 23, 11])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_89_encrypt", "language": "elixir", "prompt": "# Create a function encrypt that takes a string as an argument and\n# returns a string encrypted with the alphabet being rotated. \n# The alphabet should be rotated in a manner such that the letters \n# shift down by two multiplied to two places.\n# For example:\n# >>> HumanEval.encrypt(\"hi\")\n# \"lm\"\n# >>> HumanEval.encrypt(\"asdfghjkl\")\n# \"ewhjklnop\"\n# >>> HumanEval.encrypt(\"gf\")\n# \"kj\"\n# >>> HumanEval.encrypt(\"et\")\n# \"ix\"\n\ndefmodule HumanEval do\n  def candidate(s), do: encrypt(s)\n  def encrypt(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_89_encrypt.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'encrypt' do\n    assert \"lm\" == HumanEval.candidate(\"hi\")\n    assert \"ewhjklnop\" == HumanEval.candidate(\"asdfghjkl\")\n    assert \"kj\" == HumanEval.candidate(\"gf\")\n    assert \"ix\" == HumanEval.candidate(\"et\")\n    assert \"jeiajeaijeiak\" == HumanEval.candidate(\"faewfawefaewg\")\n    assert \"lippsqcjvmirh\" == HumanEval.candidate(\"hellomyfriend\")\n    assert \"hbdhpqrmpjylqmpyjlpmlyjrqpmqryjlpmqryjljygyjl\" == HumanEval.candidate(\"dxzdlmnilfuhmilufhlihufnmlimnufhlimnufhfucufh\")\n    assert \"e\" == HumanEval.candidate(\"a\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_8_sum_product", "language": "elixir", "prompt": "# For a given list of integers, return a tuple consisting of a sum and a product of all the integers in a list.\n# Empty sum should be equal to 0 and empty product should be equal to 1.\n# >>> HumanEval.sum_product([])\n# {0, 1}\n# >>> HumanEval.sum_product([1, 2, 3, 4])\n# {10, 24}\n\ndefmodule HumanEval do\n  def candidate(numbers), do: sum_product(numbers)\n  def sum_product(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_8_sum_product.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'sum_product' do\n    assert {0, 1} == HumanEval.candidate([])\n    assert {3, 1} == HumanEval.candidate([1, 1, 1])\n    assert {100, 0} == HumanEval.candidate([100, 0])\n    assert {15, 105} == HumanEval.candidate([3, 5, 7])\n    assert {10, 10} == HumanEval.candidate([10])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_90_next_smallest", "language": "elixir", "prompt": "# You are given a list of integers.\n# Write a function next_smallest() that returns the 2nd smallest element of the list.\n# Return None if there is no such element.\n# >>> HumanEval.next_smallest([1, 2, 3, 4, 5])\n# 2\n# >>> HumanEval.next_smallest([5, 1, 4, 3, 2])\n# 2\n# >>> HumanEval.next_smallest([])\n# nil\n# >>> HumanEval.next_smallest([1, 1])\n# nil\n\ndefmodule HumanEval do\n  def candidate(lst), do: next_smallest(lst)\n  def next_smallest(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_90_next_smallest.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'next_smallest' do\n    assert 2 == HumanEval.candidate([1, 2, 3, 4, 5])\n    assert 2 == HumanEval.candidate([5, 1, 4, 3, 2])\n    assert nil == HumanEval.candidate([])\n    assert nil == HumanEval.candidate([1, 1])\n    assert 1 == HumanEval.candidate([1, 1, 1, 1, 0])\n    assert nil == HumanEval.candidate([1, 1])\n    assert -35 == HumanEval.candidate([-35, 34, 12, -45])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_91_is_bored", "language": "elixir", "prompt": "# You'll be given a string of words, and your task is to count the number\n# of boredoms. A boredom is a sentence that starts with the word \"I\".\n# Sentences are delimited by '.', '?' or '!'.\n# For example:\n# >>> HumanEval.is_bored(\"Hello world\")\n# 0\n# >>> HumanEval.is_bored(\"The sky is blue. The sun is shining. I love this weather\")\n# 1\n\ndefmodule HumanEval do\n  def candidate(S), do: is_bored(S)\n  def is_bored(S) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_91_is_bored.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'is_bored' do\n    assert 0 == HumanEval.candidate(\"Hello world\")\n    assert 0 == HumanEval.candidate(\"Is the sky blue?\")\n    assert 1 == HumanEval.candidate(\"I love It !\")\n    assert 0 == HumanEval.candidate(\"bIt\")\n    assert 2 == HumanEval.candidate(\"I feel good today. I will be productive. will kill It\")\n    assert 0 == HumanEval.candidate(\"You and I are going for a walk\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_92_any_int", "language": "elixir", "prompt": "# Create a function that takes 3 numbers.\n# Returns true if one of the numbers is equal to the sum of the other two, and all numbers are integers.\n# Returns false in any other cases.\n# Examples\n# >>> HumanEval.any_int(5, 2, 7)\n# true\n# >>> HumanEval.any_int(3, 2, 2)\n# false\n# >>> HumanEval.any_int(3, -2, 1)\n# true\n# >>> HumanEval.any_int(3.6, -2.2, 2)\n# false\n\ndefmodule HumanEval do\n  def candidate(x, y, z), do: any_int(x, y, z)\n  def any_int(x, y, z) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_92_any_int.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'any_int' do\n    assert true == HumanEval.candidate(2, 3, 1)\n    assert false == HumanEval.candidate(2.5, 2, 3)\n    assert false == HumanEval.candidate(1.5, 5, 3.5)\n    assert false == HumanEval.candidate(2, 6, 2)\n    assert true == HumanEval.candidate(4, 2, 2)\n    assert false == HumanEval.candidate(2.2, 2.2, 2.2)\n    assert true == HumanEval.candidate(-4, 6, 2)\n    assert true == HumanEval.candidate(2, 1, 1)\n    assert true == HumanEval.candidate(3, 4, 7)\n    assert false == HumanEval.candidate(3.0, 4, 7)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_93_encode", "language": "elixir", "prompt": "# Write a function that takes a message, and encodes in such a \n# way that it swaps case of all letters, replaces all vowels in \n# the message with the letter that appears 2 places ahead of that \n# vowel in the english alphabet. \n# Assume only letters. \n# Examples:\n# >>> HumanEval.encode(\"test\")\n# \"TGST\"\n# >>> HumanEval.encode(\"This is a message\")\n# \"tHKS KS C MGSSCGG\"\n\ndefmodule HumanEval do\n  def candidate(message), do: encode(message)\n  def encode(message) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_93_encode.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'encode' do\n    assert \"tgst\" == HumanEval.candidate(\"TEST\")\n    assert \"mWDCSKR\" == HumanEval.candidate(\"Mudasir\")\n    assert \"ygs\" == HumanEval.candidate(\"YES\")\n    assert \"tHKS KS C MGSSCGG\" == HumanEval.candidate(\"This is a message\")\n    assert \"k dQnT kNqW wHcT Tq wRkTg\" == HumanEval.candidate(\"I DoNt KnOw WhAt tO WrItE\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_94_skjkasdkd", "language": "elixir", "prompt": "# You are given a list of integers.\n# You need to find the largest prime value and return the sum of its digits.\n# Examples:\n# >>> HumanEval.skjkasdkd([0, 3, 2, 1, 3, 5, 7, 4, 5, 5, 5, 2, 181, 32, 4, 32, 3, 2, 32, 324, 4, 3])\n# 10\n# >>> HumanEval.skjkasdkd([1, 0, 1, 8, 2, 4597, 2, 1, 3, 40, 1, 2, 1, 2, 4, 2, 5, 1])\n# 25\n# >>> HumanEval.skjkasdkd([1, 3, 1, 32, 5107, 34, 83278, 109, 163, 23, 2323, 32, 30, 1, 9, 3])\n# 13\n# >>> HumanEval.skjkasdkd([0, 724, 32, 71, 99, 32, 6, 0, 5, 91, 83, 0, 5, 6])\n# 11\n# >>> HumanEval.skjkasdkd([0, 81, 12, 3, 1, 21])\n# 3\n# >>> HumanEval.skjkasdkd([0, 8, 1, 2, 1, 7])\n# 7\n\ndefmodule HumanEval do\n  def candidate(lst), do: skjkasdkd(lst)\n  def skjkasdkd(lst) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_94_skjkasdkd.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'skjkasdkd' do\n    assert 10 == HumanEval.candidate([0, 3, 2, 1, 3, 5, 7, 4, 5, 5, 5, 2, 181, 32, 4, 32, 3, 2, 32, 324, 4, 3])\n    assert 25 == HumanEval.candidate([1, 0, 1, 8, 2, 4597, 2, 1, 3, 40, 1, 2, 1, 2, 4, 2, 5, 1])\n    assert 13 == HumanEval.candidate([1, 3, 1, 32, 5107, 34, 83278, 109, 163, 23, 2323, 32, 30, 1, 9, 3])\n    assert 11 == HumanEval.candidate([0, 724, 32, 71, 99, 32, 6, 0, 5, 91, 83, 0, 5, 6])\n    assert 3 == HumanEval.candidate([0, 81, 12, 3, 1, 21])\n    assert 7 == HumanEval.candidate([0, 8, 1, 2, 1, 7])\n    assert 19 == HumanEval.candidate([8191])\n    assert 19 == HumanEval.candidate([8191, 123456, 127, 7])\n    assert 10 == HumanEval.candidate([127, 97, 8192])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_95_check_dict_case", "language": "elixir", "prompt": "# Given a dictionary, return True if all keys are strings in lower \n# case or all keys are strings in upper case, else return False.\n# The function should return False is the given dictionary is empty.\n# Examples:\n# >>> HumanEval.check_dict_case(%{\"a\" => \"apple\", \"b\" => \"banana\"})\n# true\n# >>> HumanEval.check_dict_case(%{\"a\" => \"apple\", \"A\" => \"banana\", \"B\" => \"banana\"})\n# false\n# >>> HumanEval.check_dict_case(%{\"a\" => \"apple\", 8 => \"banana\", \"a\" => \"apple\"})\n# false\n# >>> HumanEval.check_dict_case(%{\"Name\" => \"John\", \"Age\" => \"36\", \"City\" => \"Houston\"})\n# false\n# >>> HumanEval.check_dict_case(%{\"STATE\" => \"NC\", \"ZIP\" => \"12345\"})\n# true\n\ndefmodule HumanEval do\n  def candidate(dict), do: check_dict_case(dict)\n  def check_dict_case(dict) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_95_check_dict_case.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'check_dict_case' do\n    assert true == HumanEval.candidate(%{\"p\" => \"pineapple\", \"b\" => \"banana\"})\n    assert false == HumanEval.candidate(%{\"p\" => \"pineapple\", \"A\" => \"banana\", \"B\" => \"banana\"})\n    assert false == HumanEval.candidate(%{\"p\" => \"pineapple\", \"5\" => \"banana\", \"a\" => \"apple\"})\n    assert false == HumanEval.candidate(%{\"Name\" => \"John\", \"Age\" => \"36\", \"City\" => \"Houston\"})\n    assert true == HumanEval.candidate(%{\"STATE\" => \"NC\", \"ZIP\" => \"12345\"})\n    assert true == HumanEval.candidate(%{\"fruit\" => \"Orange\", \"taste\" => \"Sweet\"})\n    assert false == HumanEval.candidate(%{})\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_96_count_up_to", "language": "elixir", "prompt": "# Implement a function that takes an non-negative integer and returns an array of the first n\n# integers that are prime numbers and less than n.\n# for example:\n# >>> HumanEval.count_up_to(5)\n# [2, 3]\n# >>> HumanEval.count_up_to(11)\n# [2, 3, 5, 7]\n# >>> HumanEval.count_up_to(0)\n# []\n# >>> HumanEval.count_up_to(20)\n# [2, 3, 5, 7, 11, 13, 17, 19]\n# >>> HumanEval.count_up_to(1)\n# []\n# >>> HumanEval.count_up_to(18)\n# [2, 3, 5, 7, 11, 13, 17]\n\ndefmodule HumanEval do\n  def candidate(n), do: count_up_to(n)\n  def count_up_to(n) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_96_count_up_to.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'count_up_to' do\n    assert [2, 3] == HumanEval.candidate(5)\n    assert [2, 3, 5] == HumanEval.candidate(6)\n    assert [2, 3, 5] == HumanEval.candidate(7)\n    assert [2, 3, 5, 7] == HumanEval.candidate(10)\n    assert [] == HumanEval.candidate(0)\n    assert [2, 3, 5, 7, 11, 13, 17, 19] == HumanEval.candidate(22)\n    assert [] == HumanEval.candidate(1)\n    assert [2, 3, 5, 7, 11, 13, 17] == HumanEval.candidate(18)\n    assert [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43] == HumanEval.candidate(47)\n    assert [2, 3, 5, 7, 11, 13, 17, 19, 23, 29, 31, 37, 41, 43, 47, 53, 59, 61, 67, 71, 73, 79, 83, 89, 97] == HumanEval.candidate(101)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_97_multiply", "language": "elixir", "prompt": "# Complete the function that takes two integers and returns \n# the product of their unit digits.\n# Assume the input is always valid.\n# Examples:\n# >>> HumanEval.multiply(148, 412)\n# 16\n# >>> HumanEval.multiply(19, 28)\n# 72\n# >>> HumanEval.multiply(2020, 1851)\n# 0\n# >>> HumanEval.multiply(14, -15)\n# 20\n\ndefmodule HumanEval do\n  def candidate(a, b), do: multiply(a, b)\n  def multiply(a, b) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_97_multiply.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'multiply' do\n    assert 16 == HumanEval.candidate(148, 412)\n    assert 72 == HumanEval.candidate(19, 28)\n    assert 0 == HumanEval.candidate(2020, 1851)\n    assert 20 == HumanEval.candidate(14, -15)\n    assert 42 == HumanEval.candidate(76, 67)\n    assert 49 == HumanEval.candidate(17, 27)\n    assert 0 == HumanEval.candidate(0, 1)\n    assert 0 == HumanEval.candidate(0, 0)\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_98_count_upper", "language": "elixir", "prompt": "# Given a string s, count the number of uppercase vowels in even indices.\n# For example:\n# >>> HumanEval.count_upper(\"aBCdEf\")\n# 1\n# >>> HumanEval.count_upper(\"abcdefg\")\n# 0\n# >>> HumanEval.count_upper(\"dBBE\")\n# 0\n\ndefmodule HumanEval do\n  def candidate(s), do: count_upper(s)\n  def count_upper(s) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_98_count_upper.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'count_upper' do\n    assert 1 == HumanEval.candidate(\"aBCdEf\")\n    assert 0 == HumanEval.candidate(\"abcdefg\")\n    assert 0 == HumanEval.candidate(\"dBBE\")\n    assert 0 == HumanEval.candidate(\"B\")\n    assert 1 == HumanEval.candidate(\"U\")\n    assert 0 == HumanEval.candidate(\"\")\n    assert 2 == HumanEval.candidate(\"EEEE\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_99_closest_integer", "language": "elixir", "prompt": "# Create a function that takes a value (string) representing a number\n# and returns the closest integer to it. If the number is equidistant\n# from two integers, round it away from zero.\n# Examples\n# >>> HumanEval.closest_integer(\"10\")\n# 10\n# >>> HumanEval.closest_integer(\"15.3\")\n# 15\n# Note:\n# Rounding away from zero means that if the given number is equidistant\n# from two integers, the one you should return is the one that is the\n# farthest from zero. For example closest_integer(\"14.5\") should\n# return 15 and closest_integer(\"-14.5\") should return -15.\n\ndefmodule HumanEval do\n  def candidate(value), do: closest_integer(value)\n  def closest_integer(value) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_99_closest_integer.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'closest_integer' do\n    assert 10 == HumanEval.candidate(\"10\")\n    assert 15 == HumanEval.candidate(\"14.5\")\n    assert -16 == HumanEval.candidate(\"-15.5\")\n    assert 15 == HumanEval.candidate(\"15.3\")\n    assert 0 == HumanEval.candidate(\"0\")\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
{"name": "HumanEval_9_rolling_max", "language": "elixir", "prompt": "# From a given list of integers, generate a list of rolling maximum element found until given moment\n# in the sequence.\n# >>> HumanEval.rolling_max([1, 2, 3, 2, 3, 4, 2])\n# [1, 2, 3, 3, 3, 4, 4]\n\ndefmodule HumanEval do\n  def candidate(numbers), do: rolling_max(numbers)\n  def rolling_max(numbers) do\n    ", "doctests": "transform", "original": "/home/MultiPL-E/datasets/../datasets/originals-with-cleaned-doctests/HumanEval_9_rolling_max.py", "prompt_terminology": "verbatim", "tests": "ExUnit.start()\ndefmodule HumanEvalTest do\n  use ExUnit.Case, async: true\n  test 'rolling_max' do\n    assert [] == HumanEval.candidate([])\n    assert [1, 2, 3, 4] == HumanEval.candidate([1, 2, 3, 4])\n    assert [4, 4, 4, 4] == HumanEval.candidate([4, 3, 2, 1])\n    assert [3, 3, 3, 100, 100] == HumanEval.candidate([3, 2, 3, 100, 3])\n  end\nend\n", "stop_tokens": ["\ndefmodule", "\ndefp", "\ndef ", "\n#", "\n\n"]}
